{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing (DWMW17)"
      ],
      "metadata": {
        "id": "9VYBFqSTnNSm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mxr8Iyf2Lc0Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33e3e23a-5e6c-4137-c49d-24dcc51f68b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/drive')\n",
        "path = '/drive/My Drive/CSCI544 Project/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TjZeQcybElav"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter, OrderedDict\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.optim.lr_scheduler import StepLR, MultiStepLR, CyclicLR\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# if torch.cuda.is_available():  \n",
        "#   dev = \"cuda:0\"\n",
        "#   torch.cuda.set_device(0)\n",
        "# else:  \n",
        "#   dev = \"cpu\"\n",
        "device = torch.device('cpu')"
      ],
      "metadata": {
        "id": "4qqO677HeGIh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ovsJeTvRLGGB"
      },
      "outputs": [],
      "source": [
        "# Used DWMW17 from https://github.com/t-davidson/hate-speech-and-offensive-language/tree/master/data\n",
        "data_path = 'https://raw.githubusercontent.com/t-davidson/hate-speech-and-offensive-language/master/data/labeled_data.csv'\n",
        "data = pd.read_csv(data_path)\n",
        "df = data[['class', 'tweet']].copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FjvqA-YCb0x",
        "outputId": "758dae47-4dc3-4997-dd96-265baa0a35d8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24783"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "len(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dX63IZcbcMVN",
        "outputId": "dc4603ae-0b81-490e-f6ff-557ef918b2df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-27-29da0877ee92>:7: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
            "  df['tweet'] = df['tweet'].str.replace(punct_sign, '')\n"
          ]
        }
      ],
      "source": [
        "# preprocessing\n",
        "df['tweet'] = df['tweet'].apply(lambda x:x.lower())\n",
        "punctuation_signs = list(\"?:!.,;\")\n",
        "df['tweet'] = df['tweet']\n",
        "\n",
        "for punct_sign in punctuation_signs:   \n",
        "    df['tweet'] = df['tweet'].str.replace(punct_sign, '')\n",
        "\n",
        "df['tweet'] = df['tweet'].apply(lambda x: x.replace('\\n', ' '))\n",
        "df['tweet'] = df['tweet'].apply(lambda x: x.replace('\\t', ' '))\n",
        "df['tweet'] = df['tweet'].str.replace(\"    \", \" \")\n",
        "df['tweet'] = df['tweet'].str.replace('\"', '')\n",
        "df['tweet'] = df['tweet'].str.replace(\"'s\", \"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWMwPRoXcc4I",
        "outputId": "8048be55-b848-49b1-f124-a456e848a196"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "<ipython-input-28-5e5fe2b64a04>:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  df['tweet'] = df['tweet'].str.replace(regex_stopword, '')\n"
          ]
        }
      ],
      "source": [
        "# remove stop words\n",
        "nltk.download('stopwords')\n",
        "stop_words = list(stopwords.words('english'))\n",
        "for stop_word in stop_words:\n",
        "    regex_stopword = r\"\\b\" + stop_word + r\"\\b\"\n",
        "    df['tweet'] = df['tweet'].str.replace(regex_stopword, '')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['tweet'] = df['tweet'].str.split()"
      ],
      "metadata": {
        "id": "dirtmhiCG32h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "glove_model = {}\n",
        "with open(path + 'glove.6B.100d','r') as f:\n",
        "    for line in f:\n",
        "        line = line.split()\n",
        "        word = line[0]\n",
        "        embedding = np.array(line[1:], dtype=np.float64)\n",
        "        glove_model[word] = embedding"
      ],
      "metadata": {
        "id": "9JoPcMR8NbCu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # make encoding in X match glove embedding\n",
        "vecs = np.zeros((len(glove_model), 100), dtype=np.float64)\n",
        "i = 0\n",
        "for word, embedding in glove_model.items():\n",
        "    vecs[i] = embedding\n",
        "    i += 1\n",
        "\n",
        "pad_vec = np.zeros((1,100))   # vector for padding\n",
        "\n",
        "unk_vec = np.mean(vecs, axis=0) # <unk>\n",
        "\n",
        "glove_embeddings = np.vstack((pad_vec, unk_vec, vecs))\n",
        "glove_vocab = list(glove_model.keys())\n",
        "glove_vocab.insert(0, '<unk>')\n",
        "glove_vocab.insert(0, '<pad>')\n",
        "word_index = {glove_vocab[i]:i for i in range(len(glove_vocab))}"
      ],
      "metadata": {
        "id": "Ingwx50-Nefg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = [0] * len(df)\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "  X[index] = []\n",
        "  for word in row['tweet']:\n",
        "    if word in glove_vocab:\n",
        "      X[index].append(word_index[word])\n",
        "    else:\n",
        "      X[index].append(word_index['<unk>'])"
      ],
      "metadata": {
        "id": "Pu7i9qAXOBFX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# count = 0\n",
        "# for index, row in df.iterrows():\n",
        "#   X[count] = []\n",
        "#   for word in row['tweet']:\n",
        "#     if word in glove_vocab:\n",
        "#       X[count].append(word_index[word])\n",
        "#     else:\n",
        "#       X[count].append(word_index['<unk>'])\n",
        "#   count += 1"
      ],
      "metadata": {
        "id": "N45SKSEfBzb5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = df['class']"
      ],
      "metadata": {
        "id": "z2mTx1VyONmk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mSnlyg93dd_3"
      },
      "outputs": [],
      "source": [
        "indices = np.arange(len(df))\n",
        "X_train, X_test, y_train, y_test, indices_train, indices_test = train_test_split(X, y, indices, test_size = 0.2, stratify=y, random_state=17)\n",
        "X_val, X_test, y_val, y_test, indices_val, indices_test = train_test_split(X_test, y_test, indices_test, test_size = 0.5, stratify=y_test, random_state=17)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BFMHs1uQaMQ5"
      },
      "outputs": [],
      "source": [
        "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "class TrainData(Dataset):\n",
        "    def __init__(self, X, y, transform=None):\n",
        "        self.X = torch.transpose(pad_sequence([torch.Tensor(i) for i in X], padding_value=0), 0, 1).to(device)\n",
        "        self.y = y\n",
        "        self.lengths = [len(i) for i in X]\n",
        "        self.transform = transform\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        tweet = self.X[index]\n",
        "        label = self.y.iloc[index]\n",
        "        length = self.lengths[index]\n",
        "            \n",
        "        return tweet, length, label\n",
        "\n",
        "\n",
        "class TestData(Dataset):\n",
        "    def __init__(self, X, transform=None):\n",
        "      self.X = torch.transpose(pad_sequence([torch.Tensor(i) for i in X], padding_value=0), 0, 1).to(device)\n",
        "      self.lengths = [len(i) for i in X]\n",
        "\n",
        "      self.transform = transform\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        tweet = self.X[index]\n",
        "        length = self.lengths[index]\n",
        "            \n",
        "        return tweet, length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ymVv-ek2aMTj"
      },
      "outputs": [],
      "source": [
        "train_data = TrainData(X_train, y_train, transform=transforms.ToTensor())\n",
        "val_data = TrainData(X_val, y_val, transform=transforms.ToTensor())\n",
        "batch_size = 20\n",
        "num_workers = 0\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
        "valid_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, num_workers=num_workers, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model (DWMW17)"
      ],
      "metadata": {
        "id": "nOfkiGMrnWfG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zmKsHx43aMWT"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class LSTM(nn.Module):\n",
        "    def __init__(self, input_size, embed_dim, hidden_size, num_layers, num_classes, dropout):\n",
        "        super(LSTM, self).__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = nn.Embedding.from_pretrained(torch.from_numpy(glove_embeddings).float())\n",
        "        self.lstm = nn.LSTM(embed_dim, hidden_size, num_layers, batch_first=True)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear1 = nn.Linear(hidden_size, 128)\n",
        "        self.elu = nn.ELU()\n",
        "        self.fc = nn.Linear(128 , num_classes)\n",
        "        \n",
        "    def forward(self, x, lengths):\n",
        "        # Initialize hidden states and cell states\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) # one forward, one backward, so *2\n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
        "        x = x.int().to(device)\n",
        "        out = self.embedding(x)\n",
        "        out = pack_padded_sequence(out, lengths, batch_first=True, enforce_sorted=False)\n",
        "        out, _ = self.lstm(out, (h0, c0))\n",
        "        out, _ = pad_packed_sequence(out, batch_first=True)\n",
        "        out = self.linear1(out)\n",
        "        out = self.dropout(out)\n",
        "        out = self.elu(out)\n",
        "        out = self.fc(out)\n",
        "        out = out[:, -1, :]\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_hidden = 256\n",
        "n_input = len(glove_embeddings)\n",
        "n_embed_dim = 100\n",
        "n_layers = 1\n",
        "n_classes = 3 # output layer\n",
        "dropout = 0.33\n",
        "lstm = LSTM(n_input, n_embed_dim, n_hidden, n_layers, n_classes, dropout)\n",
        "lstm.to(device)"
      ],
      "metadata": {
        "id": "j6p7-PjDt3lX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iXn9oJyf7fOH"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.5\n",
        "n_epochs = 30\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(lstm.parameters(), lr=learning_rate)\n",
        "scheduler = MultiStepLR(optimizer, milestones=[10, 20, 50], gamma=0.5)\n",
        "# scheduler = CyclicLR(optimizer, base_lr=0.005, max_lr=0.5)\n",
        "train_loss_min = np.Inf # initialize minimum validation loss\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "  # initialize train and validation loss\n",
        "  train_loss = 0\n",
        "  valid_loss = 0\n",
        "\n",
        "\n",
        "  # train\n",
        "  # mini-batch gradient descent\n",
        "  lstm.train()\n",
        "  for i, (data, lengths, target) in enumerate(train_loader):\n",
        "    # forward\n",
        "    output = lstm(data, lengths)\n",
        "    loss = criterion(output, target)\n",
        "    optimizer.zero_grad()\n",
        "    # backward\n",
        "    loss.backward()\n",
        "    # update parameters\n",
        "    optimizer.step()\n",
        "    # track training loss\n",
        "    train_loss += loss.item()\n",
        "    # scheduler.step()\n",
        "\n",
        "\n",
        "  # evaluation\n",
        "  lstm.eval()\n",
        "  for i, (data,lengths, target) in enumerate(valid_loader):\n",
        "      # forward pass\n",
        "      output = lstm(data, lengths)\n",
        "      # calculate the loss\n",
        "      loss = criterion(output, target)\n",
        "      # track validation loss\n",
        "      valid_loss += loss.item()\n",
        "\n",
        "\n",
        "  train_loss = train_loss/len(train_loader.dataset)\n",
        "  valid_loss = valid_loss/len(valid_loader.dataset)\n",
        "  \n",
        "  print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}\\tLearning Rate: {:.3f}'.format(\n",
        "      epoch+1, \n",
        "      train_loss,\n",
        "      valid_loss,\n",
        "      scheduler.get_last_lr()[0]\n",
        "      ))\n",
        "  \n",
        "  if train_loss <= train_loss_min:\n",
        "      print('Training loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
        "      train_loss_min,\n",
        "      train_loss))\n",
        "      torch.save(lstm.state_dict(), 'lstm_model.pt')\n",
        "      train_loss_min = train_loss\n",
        "\n",
        "  scheduler.step()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(lstm.state_dict(), path+'lstm_model(dwmw17).pt')"
      ],
      "metadata": {
        "id": "wEba1_KMsiBk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4E5LnysbaMaT"
      },
      "outputs": [],
      "source": [
        "# lstm.load_state_dict(torch.load(path+'lstm_model.pt'))\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def test():\n",
        "  test_data = TestData(X_test, transform=transforms.ToTensor())\n",
        "  test_loader = torch.utils.data.DataLoader(test_data, batch_size=1, \n",
        "      num_workers=num_workers)\n",
        "  y_pred = []\n",
        "  lstm.eval()\n",
        "  with torch.no_grad():\n",
        "      for data, lengths in test_loader:\n",
        "          outputs = lstm(data, lengths)\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          y_pred.append(predicted.tolist()[0])\n",
        "\n",
        "  print(\"Test Accuracy: \" + str(accuracy_score(list(y_test), y_pred)))\n",
        "  print(\"Test F1 Score: \"+ str(f1_score(list(y_test), y_pred, average='micro')))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test()"
      ],
      "metadata": {
        "id": "-b7Pe4WN-NfI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict():\n",
        "  test_data = TestData(X, transform=transforms.ToTensor())\n",
        "  test_loader = torch.utils.data.DataLoader(test_data, batch_size=1, \n",
        "      num_workers=num_workers)\n",
        "  y_pred = []\n",
        "  lstm.eval()\n",
        "  with torch.no_grad():\n",
        "      for data, lengths in test_loader:\n",
        "          outputs = lstm(data, lengths)\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          y_pred.append(predicted.tolist()[0])\n",
        "  return y_pred"
      ],
      "metadata": {
        "id": "bCdwLw-Copoz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict()"
      ],
      "metadata": {
        "id": "s9iM0IopAUwk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing (FDCL18)"
      ],
      "metadata": {
        "id": "4KcypRrbxTHj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fdcl18_data = pd.read_csv(path+'FDCL18.csv', delimiter='\\t', nrows=None, skiprows=2, header=None, names=['tweet', 'label', 'count'])"
      ],
      "metadata": {
        "id": "WO2H3LNjxZh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = fdcl18_data[['tweet', 'label']].copy()\n",
        "df1.loc[df1.label == 'hateful', 'label'] = 0\n",
        "df1.loc[df1.label == 'abusive', 'label'] = 1\n",
        "df1.loc[df1.label == 'spam', 'label'] = 2\n",
        "df1.loc[df1.label == 'normal', 'label'] = 3"
      ],
      "metadata": {
        "id": "QRXGkvSRzrpY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocessing\n",
        "df1['tweet'] = df1['tweet'].apply(lambda x:x.lower())\n",
        "punctuation_signs = list(\"?:!.,;\")\n",
        "df1['tweet'] = df1['tweet']\n",
        "\n",
        "for punct_sign in punctuation_signs:   \n",
        "    df1['tweet'] = df1['tweet'].str.replace(punct_sign, '')\n",
        "\n",
        "df1['tweet'] = df1['tweet'].apply(lambda x: x.replace('\\n', ' '))\n",
        "df1['tweet'] = df1['tweet'].apply(lambda x: x.replace('\\t', ' '))\n",
        "df1['tweet'] = df1['tweet'].str.replace(\"    \", \" \")\n",
        "df1['tweet'] = df1['tweet'].str.replace('\"', '')\n",
        "df1['tweet'] = df1['tweet'].str.replace(\"'s\", \"\")\n",
        "\n",
        "# remove stop words\n",
        "nltk.download('stopwords')\n",
        "stop_words = list(stopwords.words('english'))\n",
        "for stop_word in stop_words:\n",
        "    regex_stopword = r\"\\b\" + stop_word + r\"\\b\"\n",
        "    df1['tweet'] = df1['tweet'].str.replace(regex_stopword, '')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycUY_Kb27onN",
        "outputId": "323a899f-4997-484c-ae98-26c0642b13bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-02dd1e57637d>:7: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
            "  df1['tweet'] = df1['tweet'].str.replace(punct_sign, '')\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "<ipython-input-12-02dd1e57637d>:20: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  df1['tweet'] = df1['tweet'].str.replace(regex_stopword, '')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1['tweet'] = df1['tweet'].str.split()"
      ],
      "metadata": {
        "id": "kWD54YO78RJQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = [0] * len(df1)\n",
        "\n",
        "for index, row in df1.iterrows():\n",
        "  X[index] = []\n",
        "  for word in row['tweet']:\n",
        "    if word in glove_vocab:\n",
        "      X[index].append(word_index[word])\n",
        "    else:\n",
        "      X[index].append(word_index['<unk>'])"
      ],
      "metadata": {
        "id": "jXYX7ogH8e_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = df1['label']"
      ],
      "metadata": {
        "id": "Vnc-XtSm9JLF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "indices = np.arange(len(X))\n",
        "X_train, X_test, y_train, y_test, indices_train, indices_test = train_test_split(X, y, indices, test_size = 0.2, stratify=y, random_state=17)\n",
        "X_val, X_test, y_val, y_test, indices_val, indices_test = train_test_split(X_test, y_test, indices_test, test_size = 0.5, stratify=y_test, random_state=17)"
      ],
      "metadata": {
        "id": "dsOmYm8v8-VO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = TrainData(X_train, y_train, transform=transforms.ToTensor())\n",
        "val_data = TrainData(X_val, y_val, transform=transforms.ToTensor())\n",
        "batch_size = 60\n",
        "num_workers = 0\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
        "valid_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size, num_workers=num_workers, shuffle=True)"
      ],
      "metadata": {
        "id": "GbKrUHiz9El2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model (FDCL18)"
      ],
      "metadata": {
        "id": "qfJvO4AZ6eTa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_hidden = 256\n",
        "n_input = len(glove_embeddings)\n",
        "n_embed_dim = 100\n",
        "n_layers = 1\n",
        "n_classes = 4 # output layer\n",
        "dropout = 0.33\n",
        "lstm = LSTM(n_input, n_embed_dim, n_hidden, n_layers, n_classes, dropout)\n",
        "lstm.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VB8jJdAq6hGn",
        "outputId": "ab64ecae-a6b3-4183-956c-97b5ab1b490a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTM(\n",
              "  (embedding): Embedding(400002, 100)\n",
              "  (lstm): LSTM(100, 256, batch_first=True)\n",
              "  (dropout): Dropout(p=0.33, inplace=False)\n",
              "  (linear1): Linear(in_features=256, out_features=128, bias=True)\n",
              "  (elu): ELU(alpha=1.0)\n",
              "  (fc): Linear(in_features=128, out_features=4, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2plwvU-14YG_",
        "outputId": "49d76a98-5f5b-4a87-be91-b834ce117770"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 \tTraining Loss: 0.018595 \tValidation Loss: 0.018690\tLearning Rate: 0.500\n",
            "Training loss decreased (inf --> 0.018595).  Saving model ...\n",
            "Epoch: 2 \tTraining Loss: 0.018527 \tValidation Loss: 0.018560\tLearning Rate: 0.500\n",
            "Training loss decreased (0.018595 --> 0.018527).  Saving model ...\n",
            "Epoch: 3 \tTraining Loss: 0.018458 \tValidation Loss: 0.018463\tLearning Rate: 0.500\n",
            "Training loss decreased (0.018527 --> 0.018458).  Saving model ...\n",
            "Epoch: 4 \tTraining Loss: 0.018444 \tValidation Loss: 0.018467\tLearning Rate: 0.500\n",
            "Training loss decreased (0.018458 --> 0.018444).  Saving model ...\n",
            "Epoch: 5 \tTraining Loss: 0.018424 \tValidation Loss: 0.018536\tLearning Rate: 0.500\n",
            "Training loss decreased (0.018444 --> 0.018424).  Saving model ...\n",
            "Epoch: 6 \tTraining Loss: 0.018426 \tValidation Loss: 0.018495\tLearning Rate: 0.500\n",
            "Epoch: 7 \tTraining Loss: 0.018410 \tValidation Loss: 0.018455\tLearning Rate: 0.500\n",
            "Training loss decreased (0.018424 --> 0.018410).  Saving model ...\n",
            "Epoch: 8 \tTraining Loss: 0.018407 \tValidation Loss: 0.018569\tLearning Rate: 0.500\n",
            "Training loss decreased (0.018410 --> 0.018407).  Saving model ...\n",
            "Epoch: 9 \tTraining Loss: 0.018411 \tValidation Loss: 0.018449\tLearning Rate: 0.500\n",
            "Epoch: 10 \tTraining Loss: 0.018409 \tValidation Loss: 0.018532\tLearning Rate: 0.500\n",
            "Epoch: 11 \tTraining Loss: 0.018369 \tValidation Loss: 0.018520\tLearning Rate: 0.250\n",
            "Training loss decreased (0.018407 --> 0.018369).  Saving model ...\n",
            "Epoch: 12 \tTraining Loss: 0.018358 \tValidation Loss: 0.018383\tLearning Rate: 0.250\n",
            "Training loss decreased (0.018369 --> 0.018358).  Saving model ...\n",
            "Epoch: 13 \tTraining Loss: 0.018367 \tValidation Loss: 0.018408\tLearning Rate: 0.250\n",
            "Epoch: 14 \tTraining Loss: 0.018357 \tValidation Loss: 0.018471\tLearning Rate: 0.250\n",
            "Training loss decreased (0.018358 --> 0.018357).  Saving model ...\n",
            "Epoch: 15 \tTraining Loss: 0.018368 \tValidation Loss: 0.018415\tLearning Rate: 0.250\n",
            "Epoch: 16 \tTraining Loss: 0.018346 \tValidation Loss: 0.018467\tLearning Rate: 0.250\n",
            "Training loss decreased (0.018357 --> 0.018346).  Saving model ...\n",
            "Epoch: 17 \tTraining Loss: 0.018345 \tValidation Loss: 0.018386\tLearning Rate: 0.250\n",
            "Training loss decreased (0.018346 --> 0.018345).  Saving model ...\n",
            "Epoch: 18 \tTraining Loss: 0.018361 \tValidation Loss: 0.018459\tLearning Rate: 0.250\n",
            "Epoch: 19 \tTraining Loss: 0.018352 \tValidation Loss: 0.018416\tLearning Rate: 0.250\n",
            "Epoch: 20 \tTraining Loss: 0.018351 \tValidation Loss: 0.018395\tLearning Rate: 0.250\n"
          ]
        }
      ],
      "source": [
        "learning_rate = 0.5\n",
        "n_epochs = 20\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(lstm.parameters(), lr=learning_rate)\n",
        "scheduler = MultiStepLR(optimizer, milestones=[10, 20, 50], gamma=0.5)\n",
        "# scheduler = CyclicLR(optimizer, base_lr=0.005, max_lr=0.5)\n",
        "train_loss_min = np.Inf # initialize minimum validation loss\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "  # initialize train and validation loss\n",
        "  train_loss = 0\n",
        "  valid_loss = 0\n",
        "\n",
        "\n",
        "  # train\n",
        "  # mini-batch gradient descent\n",
        "  lstm.train()\n",
        "  for i, (data, lengths, target) in enumerate(train_loader):\n",
        "    # forward\n",
        "    output = lstm(data, lengths)\n",
        "    loss = criterion(output, target)\n",
        "    optimizer.zero_grad()\n",
        "    # backward\n",
        "    loss.backward()\n",
        "    # update parameters\n",
        "    optimizer.step()\n",
        "    # track training loss\n",
        "    train_loss += loss.item()\n",
        "    # scheduler.step()\n",
        "\n",
        "\n",
        "  # evaluation\n",
        "  lstm.eval()\n",
        "  for i, (data,lengths, target) in enumerate(valid_loader):\n",
        "      # forward pass\n",
        "      output = lstm(data, lengths)\n",
        "      # calculate the loss\n",
        "      loss = criterion(output, target)\n",
        "      # track validation loss\n",
        "      valid_loss += loss.item()\n",
        "\n",
        "\n",
        "  train_loss = train_loss/len(train_loader.dataset)\n",
        "  valid_loss = valid_loss/len(valid_loader.dataset)\n",
        "  \n",
        "  print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}\\tLearning Rate: {:.3f}'.format(\n",
        "      epoch+1, \n",
        "      train_loss,\n",
        "      valid_loss,\n",
        "      scheduler.get_last_lr()[0]\n",
        "      ))\n",
        "  \n",
        "  if train_loss <= train_loss_min:\n",
        "      print('Training loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
        "      train_loss_min,\n",
        "      train_loss))\n",
        "      torch.save(lstm.state_dict(), 'lstm_model.pt')\n",
        "      train_loss_min = train_loss\n",
        "\n",
        "  scheduler.step()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(lstm.state_dict(), path+'lstm_model(fdcl18).pt')"
      ],
      "metadata": {
        "id": "tBuego-R-SOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lstm.load_state_dict(torch.load(path+'lstm_model(fdcl18).pt'))\n",
        "test()\n",
        "y_pred = predict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRIOeNGBAZ2Z",
        "outputId": "2220a09d-7544-42e3-c0ad-076feff126a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.7652\n",
            "Test F1 Score: 0.7652\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1['pred'] = y_pred\n",
        "with open(path+'lstm_pred(fdcl18).csv', 'w') as f:\n",
        "  f.write('tweet,label,pred')\n",
        "  for index, row in df1.iterrows():\n",
        "    f.write(str(row['tweet'])+ ',' + str(row['label']) + ','+ str(row['pred']))"
      ],
      "metadata": {
        "id": "S01wsVNV6vt3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgLPExad7imb"
      },
      "source": [
        "# LSTM Bias Evalutaion (DWMW16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HyL5pmm2m9qu"
      },
      "outputs": [],
      "source": [
        "# African-American, Hispanic, Asian, and White topics,\n",
        "aae = np.genfromtxt(path+'aae.txt', delimiter=',')\n",
        "df['race'] = aae.argmax(axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wpa_U-ALms--"
      },
      "outputs": [],
      "source": [
        "lstm_result = df.copy()\n",
        "lstm_result = lstm_result.reindex(np.arange(len(X)))\n",
        "lstm_result.loc[indices_train, 'data_type'] = 'train'\n",
        "lstm_result.loc[indices_val, 'data_type'] = 'val'\n",
        "lstm_result.loc[indices_test, 'data_type'] = 'test'\n",
        "lstm_result['pred'] = y_pred\n",
        "lstm_result = lstm_result.loc[lstm_result['data_type']=='test'][['class', 'pred', 'race']]\n",
        "aae_group = lstm_result.loc[lstm_result['race'] == 0]\n",
        "other_group = lstm_result.loc[lstm_result['race'] != 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4PhcoLJOMY-9"
      },
      "outputs": [],
      "source": [
        "def fpr(cm):\n",
        "  FP = cm.sum(axis=0) - np.diag(cm)  \n",
        "  FN = cm.sum(axis=1) - np.diag(cm)\n",
        "  TP = np.diag(cm)\n",
        "  TN = cm.sum() - (FP + FN + TP)\n",
        "  FPR = FP/(FP+TN)\n",
        "  return FPR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c8yfOeEk4IwC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "431cae87-20e8-4d38-c8fa-58f8575b6d0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSTM Bias Evaluation: \n",
            "\tHate Speech Offensive  Neither\n",
            "AAE\t[0.00077519 0.65322581 0.02340094]\n",
            "Non-AAE\t[0.01912046 0.34862385 0.08076923]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "print(\"LSTM Bias Evaluation (DWMW16): \")\n",
        "print('\\tHate Speech' + ' Offensive' + '  Neither')\n",
        "aae_cm = confusion_matrix(aae_group['class'], aae_group['pred'])\n",
        "print(\"AAE\" + '\\t' + str(fpr(aae_cm)))\n",
        "other_cm = confusion_matrix(other_group['class'], other_group['pred'])\n",
        "print(\"Non-AAE\" + '\\t' + str(fpr(other_cm)))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bert Bias Evaluation (DWMW16)"
      ],
      "metadata": {
        "id": "yrk6ORIiOLLR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bert = pd.read_csv(path+'preds.csv')\n",
        "bert['race'] = aae.argmax(axis=1)\n",
        "bert = bert.loc[bert['data_type']=='test'][['label', 'pred', 'race']]"
      ],
      "metadata": {
        "id": "6mAp8WzBOPkQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aae_group = bert.loc[bert['race'] == 0]\n",
        "other_group = bert.loc[bert['race'] != 0]"
      ],
      "metadata": {
        "id": "gf7ZkMnNPJsE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "print(\"BERT Bias Evaluation: \")\n",
        "print('\\tHate Speech' + ' Offensive' + '  Neither')\n",
        "aae_cm = confusion_matrix(aae_group['label'], aae_group['pred'])\n",
        "print(\"AAE\" + '\\t' + str(fpr(aae_cm)))\n",
        "other_cm = confusion_matrix(other_group['label'], other_group['pred'])\n",
        "print(\"Non-AAE\" + '\\t' + str(fpr(other_cm)))"
      ],
      "metadata": {
        "id": "pPZ50hI6PNZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM Bias Evaluation (FDCL18)"
      ],
      "metadata": {
        "id": "CpYPvn3fHk46"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aae = np.genfromtxt(path+'fdcl18_aae.csv', delimiter=',')\n",
        "df1['race'] = aae.argmax(axis=1)"
      ],
      "metadata": {
        "id": "0PilupRdHswv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_result = df1.copy()\n",
        "lstm_result.loc[indices_train, 'data_type'] = 'train'\n",
        "lstm_result.loc[indices_val, 'data_type'] = 'val'\n",
        "lstm_result.loc[indices_test, 'data_type'] = 'test'\n",
        "lstm_result['pred'] = y_pred\n",
        "# lstm_result['race'] = aae.argmax(axis=1)\n",
        "lstm_result = lstm_result.loc[lstm_result['data_type']=='test'][['label', 'pred', 'race']]\n",
        "aae_group = lstm_result.loc[lstm_result['race'] == 0]\n",
        "other_group = lstm_result.loc[lstm_result['race'] != 0]"
      ],
      "metadata": {
        "id": "ITh54zzBJCkb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "print(\"LSTM Bias Evaluation (FDCL18): \")\n",
        "print('\\tHateful' + ' Abusive' + '  Spam' + '  Normal')\n",
        "aae_cm = confusion_matrix(list(aae_group['label']), list(aae_group['pred']))\n",
        "print(\"AAE\" + '\\t' + str(fpr(aae_cm)))\n",
        "other_cm = confusion_matrix(list(other_group['label']), list(other_group['pred']))\n",
        "print(\"Non-AAE\" + '\\t' + str(fpr(other_cm)))"
      ],
      "metadata": {
        "id": "9YS9jXNHWaDv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "089566b4-3d4a-44e2-f530-b4b71faba01b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSTM Bias Evaluation (FDCL18): \n",
            "\tHateful Abusive  Spam  Normal\n",
            "AAE\t[0.         0.38049713 0.08803828 0.05355191]\n",
            "Non-AAE\t[0.         0.08651287 0.14631886 0.17216216]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bert Bias Evaluation (FDCL18)"
      ],
      "metadata": {
        "id": "FlBkhL08MGP6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bert = pd.read_csv(path+'FDCL_results(bert).csv')\n",
        "bert['race'] = aae.argmax(axis=1)\n",
        "bert = bert.loc[bert['data_type']=='test'][['label', 'pred', 'race']]"
      ],
      "metadata": {
        "id": "2eoxf7CGMFdD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aae_group = bert.loc[bert['race'] == 0]\n",
        "other_group = bert.loc[bert['race'] != 0]"
      ],
      "metadata": {
        "id": "D6xgZWu1MLRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "print(\"BERT Bias Evaluation: \")\n",
        "print('\\tHateful' + ' Abusive' + '  Spam' + '  Normal')\n",
        "aae_cm = confusion_matrix(aae_group['label'], aae_group['pred'])\n",
        "print(\"AAE\" + '\\t' + str(fpr(aae_cm)))\n",
        "other_cm = confusion_matrix(other_group['label'], other_group['pred'])\n",
        "print(\"Non-AAE\" + '\\t' + str(fpr(other_cm)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WN5IEONFMNoR",
        "outputId": "81cac3e0-bee7-4394-c50f-d60dd7385671"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT Bias Evaluation: \n",
            "\tHateful Abusive  Spam  Normal\n",
            "AAE\t[0.0464666  0.19311663 0.0507177  0.04918033]\n",
            "Non-AAE\t[0.01676505 0.04658385 0.06355932 0.19972973]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjpQzx9peonQ"
      },
      "source": [
        "# References:\n",
        "https://stackoverflow.com/questions/31324218/scikit-learn-how-to-obtain-true-positive-true-negative-false-positive-and-fal"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}