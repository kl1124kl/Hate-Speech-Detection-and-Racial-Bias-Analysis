{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VYBFqSTnNSm"
      },
      "source": [
        "# Data Preprocessing (DWMW17)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mxr8Iyf2Lc0Q",
        "outputId": "5d549bf2-91e7-4b5f-f69f-1b4d3f048b0b"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/drive')\n",
        "path = '/drive/My Drive/CSCI544 Project/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TjZeQcybElav"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter, OrderedDict\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.optim.lr_scheduler import StepLR, MultiStepLR, CyclicLR\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "4qqO677HeGIh"
      },
      "outputs": [],
      "source": [
        "# if torch.cuda.is_available():  \n",
        "#   dev = \"cuda:0\"\n",
        "#   torch.cuda.set_device(0)\n",
        "# else:  \n",
        "#   dev = \"cpu\"\n",
        "device = torch.device('cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ovsJeTvRLGGB"
      },
      "outputs": [],
      "source": [
        "# Used DWMW17 from https://github.com/t-davidson/hate-speech-and-offensive-language/tree/master/data\n",
        "data_path = 'https://raw.githubusercontent.com/t-davidson/hate-speech-and-offensive-language/master/data/labeled_data.csv'\n",
        "data = pd.read_csv(data_path)\n",
        "df = data[['class', 'tweet']].copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FjvqA-YCb0x",
        "outputId": "a9c92adf-64bd-44ef-ad09-aea9e1dcfd72"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "24783"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "VRUkCxn_5Mai",
        "outputId": "32e54734-4d87-4134-d32f-843f2ddbc0b4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   class                                              tweet\n",
              "0      2  !!! RT @mayasolovely: As a woman you shouldn't...\n",
              "1      1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...\n",
              "2      1  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...\n",
              "3      1  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...\n",
              "4      1  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you..."
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dX63IZcbcMVN",
        "outputId": "d9463608-57d5-4963-eea4-37f07bc40e34"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/b0/1rd8yjhd26992klldm8y9hgr0000gn/T/ipykernel_87492/3602563108.py:7: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
            "  df['tweet'] = df['tweet'].str.replace(punct_sign, '')\n"
          ]
        }
      ],
      "source": [
        "# preprocessing\n",
        "df['tweet'] = df['tweet'].apply(lambda x:x.lower())\n",
        "punctuation_signs = list(\"?:!.,;\")\n",
        "df['tweet'] = df['tweet']\n",
        "\n",
        "for punct_sign in punctuation_signs:   \n",
        "    df['tweet'] = df['tweet'].str.replace(punct_sign, '')\n",
        "\n",
        "df['tweet'] = df['tweet'].apply(lambda x: x.replace('\\n', ' '))\n",
        "df['tweet'] = df['tweet'].apply(lambda x: x.replace('\\t', ' '))\n",
        "df['tweet'] = df['tweet'].str.replace(\"    \", \" \")\n",
        "df['tweet'] = df['tweet'].str.replace('\"', '')\n",
        "df['tweet'] = df['tweet'].str.replace(\"'s\", \"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWMwPRoXcc4I",
        "outputId": "8fc38ddc-3a47-4532-d65f-2dc99cb5c74d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/luvlzf/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "/var/folders/b0/1rd8yjhd26992klldm8y9hgr0000gn/T/ipykernel_87492/398964834.py:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  df['tweet'] = df['tweet'].str.replace(regex_stopword, '')\n"
          ]
        }
      ],
      "source": [
        "# remove stop words\n",
        "nltk.download('stopwords')\n",
        "stop_words = list(stopwords.words('english'))\n",
        "for stop_word in stop_words:\n",
        "    regex_stopword = r\"\\b\" + stop_word + r\"\\b\"\n",
        "    df['tweet'] = df['tweet'].str.replace(regex_stopword, '')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "wnVS_DLz5Mao",
        "outputId": "23307bb4-444e-4ec1-e378-c0b358d858c4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "      <th>tweet</th>\n",
              "      <th>race</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>rt @mayasolovely   woman  ' complain  cleanin...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>rt @mleew17 boy dats coldtyga dwn bad  cuffin...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>rt @urkindofbrand dawg rt @80sbaby4life  ever...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>rt @c_g_anderson @viva_based  look like  tranny</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>rt @shenikaroberts  shit  hear   might  true ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>@t_madison_x  shit  blows meclaim   faithful  ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>@__brighterdays     sit   hate  another bitch ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>&amp;#8220@selfiequeenbri cause ' tired   big bitc...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>&amp;amp  might  get ya bitch back &amp;amp thats</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>@rhythmixx_ hobbies include fighting mariam  ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   class                                              tweet  race\n",
              "0      2   rt @mayasolovely   woman  ' complain  cleanin...     3\n",
              "1      1   rt @mleew17 boy dats coldtyga dwn bad  cuffin...     0\n",
              "2      1   rt @urkindofbrand dawg rt @80sbaby4life  ever...     0\n",
              "3      1    rt @c_g_anderson @viva_based  look like  tranny     0\n",
              "4      1   rt @shenikaroberts  shit  hear   might  true ...     0\n",
              "5      1  @t_madison_x  shit  blows meclaim   faithful  ...     0\n",
              "6      1  @__brighterdays     sit   hate  another bitch ...     0\n",
              "7      1  &#8220@selfiequeenbri cause ' tired   big bitc...     0\n",
              "8      1        &amp  might  get ya bitch back &amp thats       0\n",
              "9      1   @rhythmixx_ hobbies include fighting mariam  ...     0"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "aae = np.genfromtxt('aae.txt', delimiter=',')\n",
        "df['race'] = aae.argmax(axis=1)\n",
        "df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "dirtmhiCG32h"
      },
      "outputs": [],
      "source": [
        "df['tweet'] = df['tweet'].str.split()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "vOPBDu5e5Maq"
      },
      "outputs": [],
      "source": [
        "def is_toxic(class_type):\n",
        "    if class_type == 0 or class_type == 1:\n",
        "        return 'toxic' # toxic\n",
        "    else:\n",
        "        return 'non-toxic' # non-toxic\n",
        "    \n",
        "df['toxic'] = df['class'].apply(is_toxic)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "cnrZ6jTQ5Mar"
      },
      "outputs": [],
      "source": [
        "indices = np.arange(len(df))\n",
        "X_train, X_test, y_train, y_test = train_test_split(df[['class', 'tweet', 'race']], df['toxic'], test_size = 0.2, stratify=df['toxic'], random_state=17)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size = 0.5, stratify=y_test, random_state=17)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhU3g43d5Mat"
      },
      "source": [
        "### Resample training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "LsF5Z51A5Mau"
      },
      "outputs": [],
      "source": [
        "from imblearn.under_sampling import RandomUnderSampler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "gt28ajVb5Maw"
      },
      "outputs": [],
      "source": [
        "# Separate the features and labels\n",
        "X = X_train # 0 African American, 1, 2, 3\n",
        "y = y_train # 0 toxic, 1 non-toxic\n",
        "\n",
        "# Split the data into AAE and non-AAE\n",
        "X_aae = X[X['race'] == 0]\n",
        "X_non_aae = X[X['race'] != 0]\n",
        "y_aae = y[X['race'] == 0]\n",
        "y_non_aae = y[X['race'] != 0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "BCKbuB4U5Max",
        "outputId": "272cda4b-1c5f-45b3-ff06-4d28323333d4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "      <th>tweet</th>\n",
              "      <th>race</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>15209</th>\n",
              "      <td>1</td>\n",
              "      <td>[rt, @flyoutchase, saw, men, saying, arguing, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8505</th>\n",
              "      <td>1</td>\n",
              "      <td>[come, lil, bitch, want, sloppy, toppy]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14232</th>\n",
              "      <td>1</td>\n",
              "      <td>[rt, @assholeofdayear, beyonce, made, many, ho...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5653</th>\n",
              "      <td>1</td>\n",
              "      <td>[@brendacoyt_3, got, bitches, snowboarding, &amp;#...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21303</th>\n",
              "      <td>1</td>\n",
              "      <td>[tell, hater, said, fuck, tell, bitch, said, f...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15478</th>\n",
              "      <td>1</td>\n",
              "      <td>[rt, @hi_niamani, @clemheem, grandma, got, twe...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19479</th>\n",
              "      <td>1</td>\n",
              "      <td>[rt, @kxngtae, niggas, cheat, girl, stalk, cal...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4043</th>\n",
              "      <td>1</td>\n",
              "      <td>[@marshallsots, tryna, say, ', pussy, course, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3429</th>\n",
              "      <td>1</td>\n",
              "      <td>[@huntermoore, hells, yeah, fuckin, sick, ass,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5317</th>\n",
              "      <td>1</td>\n",
              "      <td>[@_kaeejones, lmaooo, boy, thought, ws, type, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10534 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       class                                              tweet  race\n",
              "15209      1  [rt, @flyoutchase, saw, men, saying, arguing, ...     0\n",
              "8505       1            [come, lil, bitch, want, sloppy, toppy]     0\n",
              "14232      1  [rt, @assholeofdayear, beyonce, made, many, ho...     0\n",
              "5653       1  [@brendacoyt_3, got, bitches, snowboarding, &#...     0\n",
              "21303      1  [tell, hater, said, fuck, tell, bitch, said, f...     0\n",
              "...      ...                                                ...   ...\n",
              "15478      1  [rt, @hi_niamani, @clemheem, grandma, got, twe...     0\n",
              "19479      1  [rt, @kxngtae, niggas, cheat, girl, stalk, cal...     0\n",
              "4043       1  [@marshallsots, tryna, say, ', pussy, course, ...     0\n",
              "3429       1  [@huntermoore, hells, yeah, fuckin, sick, ass,...     0\n",
              "5317       1  [@_kaeejones, lmaooo, boy, thought, ws, type, ...     0\n",
              "\n",
              "[10534 rows x 3 columns]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_non_aae\n",
        "X_aae"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFo-EBey5May",
        "outputId": "56931c8d-6769-47aa-8dc5-6ef0da9ee6d6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "20025        toxic\n",
              "21514    non-toxic\n",
              "17727    non-toxic\n",
              "13016        toxic\n",
              "11453    non-toxic\n",
              "           ...    \n",
              "4133         toxic\n",
              "1066         toxic\n",
              "14323        toxic\n",
              "22796    non-toxic\n",
              "18558    non-toxic\n",
              "Name: toxic, Length: 9292, dtype: object"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_non_aae"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OERNP8IQ5Maz",
        "outputId": "38490c1b-e0a5-460a-84bd-a36fedaf858c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2785\n",
            "6507\n"
          ]
        }
      ],
      "source": [
        "# Calculate the non-toxic to toxic ratio in non-AAE\n",
        "print(sum(y_non_aae == 'non-toxic'))\n",
        "print(sum(y_non_aae == 'toxic'))\n",
        "ratio_non_aae = sum(y_non_aae == 'non-toxic') / sum(y_non_aae == 'toxic')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PfAcia6Z5Ma0",
        "outputId": "af59d733-e115-492c-a1f8-1a7b59fe0b20"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.4280006147226064"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ratio_non_aae"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSdR24Hj5Ma2",
        "outputId": "46f4d9c6-a29c-4542-e4b8-e19b0f45af3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "545\n",
            "9989\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.05456001601761938"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Calculate the non-toxic to toxic ratio in AAE\n",
        "print(sum(y_aae == 'non-toxic'))\n",
        "print(sum(y_aae == 'toxic'))\n",
        "ratio_aae = sum(y_aae == 'non-toxic') / sum(y_aae == 'toxic')\n",
        "ratio_aae"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUKnHz075Ma3"
      },
      "source": [
        "Augment the training data to satisfy P(toxic|AAE) / P(non-toxic|AAE) =P(toxic|non-AAE) / P(non-toxic|non-AAE). <br>\n",
        " For example, if initially in non-AAE data, the ratio of non-toxic to toxic data is 5:1, and in AAE data, the ratio is 2:1, <br>\n",
        " then you want to upsample the data that are both AAE and non-toxic, so that the ratio in AAE data can become 5:1. <br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "FgqSS3Hf5Ma3"
      },
      "outputs": [],
      "source": [
        "# Undersample the toxic tweets in AAE to match the ratio in non-AAE\n",
        "rus = RandomUnderSampler(sampling_strategy={ 'toxic': int(sum(y_aae == 'non-toxic') / ratio_non_aae) })\n",
        "X_aae_resampled, y_aae_resampled = rus.fit_resample(X_aae, y_aae)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "oeGNmJKn5Ma4"
      },
      "outputs": [],
      "source": [
        "# Combine the oversampled AAE data and the non-AAE data\n",
        "X_resampled = pd.concat([X_non_aae, X_aae_resampled])\n",
        "y_resampled = pd.concat([y_non_aae, y_aae_resampled])\n",
        "\n",
        "# Combine the features and labels back into a data frame\n",
        "df_resampled = pd.concat([X_resampled, y_resampled], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "bMCJMpOb5Ma4",
        "outputId": "c4ef6e7e-a8a4-4b3d-dde4-0189b533da52"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "      <th>tweet</th>\n",
              "      <th>race</th>\n",
              "      <th>toxic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>20025</th>\n",
              "      <td>1</td>\n",
              "      <td>[rt, @skyereyes_, &amp;#8220@feebito_23, lol, ', f...</td>\n",
              "      <td>1</td>\n",
              "      <td>toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21514</th>\n",
              "      <td>2</td>\n",
              "      <td>[yankees, still, suck, @nikaaaa3]</td>\n",
              "      <td>3</td>\n",
              "      <td>non-toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17727</th>\n",
              "      <td>2</td>\n",
              "      <td>[rt, @thestrangelog, nerf, hell, birds, longer...</td>\n",
              "      <td>3</td>\n",
              "      <td>non-toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13016</th>\n",
              "      <td>1</td>\n",
              "      <td>[dad, told, @yourdudeferg, dad, text, one, fri...</td>\n",
              "      <td>3</td>\n",
              "      <td>toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11453</th>\n",
              "      <td>2</td>\n",
              "      <td>[isis, supporters, america, jihadis, next, doo...</td>\n",
              "      <td>3</td>\n",
              "      <td>non-toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1813</th>\n",
              "      <td>1</td>\n",
              "      <td>[soon, u, get, pt, ', wonder, go, hard, hoes, ...</td>\n",
              "      <td>0</td>\n",
              "      <td>toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1814</th>\n",
              "      <td>1</td>\n",
              "      <td>[', bitch, caught, body, week, ago, fuck, us, ...</td>\n",
              "      <td>0</td>\n",
              "      <td>toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1815</th>\n",
              "      <td>1</td>\n",
              "      <td>[rt, @chelseypaige42, bitches, begging, love, ...</td>\n",
              "      <td>0</td>\n",
              "      <td>toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1816</th>\n",
              "      <td>1</td>\n",
              "      <td>[yeen, real, nicca, yeen, got, porn, sites, n,...</td>\n",
              "      <td>0</td>\n",
              "      <td>toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1817</th>\n",
              "      <td>1</td>\n",
              "      <td>[@goldee_locx, lmao, real, shit, though, bitch...</td>\n",
              "      <td>0</td>\n",
              "      <td>toxic</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11110 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       class                                              tweet  race  \\\n",
              "20025      1  [rt, @skyereyes_, &#8220@feebito_23, lol, ', f...     1   \n",
              "21514      2                  [yankees, still, suck, @nikaaaa3]     3   \n",
              "17727      2  [rt, @thestrangelog, nerf, hell, birds, longer...     3   \n",
              "13016      1  [dad, told, @yourdudeferg, dad, text, one, fri...     3   \n",
              "11453      2  [isis, supporters, america, jihadis, next, doo...     3   \n",
              "...      ...                                                ...   ...   \n",
              "1813       1  [soon, u, get, pt, ', wonder, go, hard, hoes, ...     0   \n",
              "1814       1  [', bitch, caught, body, week, ago, fuck, us, ...     0   \n",
              "1815       1  [rt, @chelseypaige42, bitches, begging, love, ...     0   \n",
              "1816       1  [yeen, real, nicca, yeen, got, porn, sites, n,...     0   \n",
              "1817       1  [@goldee_locx, lmao, real, shit, though, bitch...     0   \n",
              "\n",
              "           toxic  \n",
              "20025      toxic  \n",
              "21514  non-toxic  \n",
              "17727  non-toxic  \n",
              "13016      toxic  \n",
              "11453  non-toxic  \n",
              "...          ...  \n",
              "1813       toxic  \n",
              "1814       toxic  \n",
              "1815       toxic  \n",
              "1816       toxic  \n",
              "1817       toxic  \n",
              "\n",
              "[11110 rows x 4 columns]"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_resampled # X_train and y_train concatenated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "e1dc_Irk5Ma4"
      },
      "outputs": [],
      "source": [
        "X_train = df_resampled[['tweet', 'race', 'toxic']]\n",
        "y_train = df_resampled['class']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "r-t88G9N5Ma5",
        "outputId": "5c43c8e0-d271-4c90-9296-d0e1e5a064f7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>race</th>\n",
              "      <th>toxic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>20025</th>\n",
              "      <td>[rt, @skyereyes_, &amp;#8220@feebito_23, lol, ', f...</td>\n",
              "      <td>1</td>\n",
              "      <td>toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21514</th>\n",
              "      <td>[yankees, still, suck, @nikaaaa3]</td>\n",
              "      <td>3</td>\n",
              "      <td>non-toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17727</th>\n",
              "      <td>[rt, @thestrangelog, nerf, hell, birds, longer...</td>\n",
              "      <td>3</td>\n",
              "      <td>non-toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13016</th>\n",
              "      <td>[dad, told, @yourdudeferg, dad, text, one, fri...</td>\n",
              "      <td>3</td>\n",
              "      <td>toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11453</th>\n",
              "      <td>[isis, supporters, america, jihadis, next, doo...</td>\n",
              "      <td>3</td>\n",
              "      <td>non-toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1813</th>\n",
              "      <td>[soon, u, get, pt, ', wonder, go, hard, hoes, ...</td>\n",
              "      <td>0</td>\n",
              "      <td>toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1814</th>\n",
              "      <td>[', bitch, caught, body, week, ago, fuck, us, ...</td>\n",
              "      <td>0</td>\n",
              "      <td>toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1815</th>\n",
              "      <td>[rt, @chelseypaige42, bitches, begging, love, ...</td>\n",
              "      <td>0</td>\n",
              "      <td>toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1816</th>\n",
              "      <td>[yeen, real, nicca, yeen, got, porn, sites, n,...</td>\n",
              "      <td>0</td>\n",
              "      <td>toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1817</th>\n",
              "      <td>[@goldee_locx, lmao, real, shit, though, bitch...</td>\n",
              "      <td>0</td>\n",
              "      <td>toxic</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11110 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   tweet  race      toxic\n",
              "20025  [rt, @skyereyes_, &#8220@feebito_23, lol, ', f...     1      toxic\n",
              "21514                  [yankees, still, suck, @nikaaaa3]     3  non-toxic\n",
              "17727  [rt, @thestrangelog, nerf, hell, birds, longer...     3  non-toxic\n",
              "13016  [dad, told, @yourdudeferg, dad, text, one, fri...     3      toxic\n",
              "11453  [isis, supporters, america, jihadis, next, doo...     3  non-toxic\n",
              "...                                                  ...   ...        ...\n",
              "1813   [soon, u, get, pt, ', wonder, go, hard, hoes, ...     0      toxic\n",
              "1814   [', bitch, caught, body, week, ago, fuck, us, ...     0      toxic\n",
              "1815   [rt, @chelseypaige42, bitches, begging, love, ...     0      toxic\n",
              "1816   [yeen, real, nicca, yeen, got, porn, sites, n,...     0      toxic\n",
              "1817   [@goldee_locx, lmao, real, shit, though, bitch...     0      toxic\n",
              "\n",
              "[11110 rows x 3 columns]"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8nYhMrG5Ma5",
        "outputId": "23b8432c-4e84-4745-d3de-fbf57fac92d8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "20025    1\n",
              "21514    2\n",
              "17727    2\n",
              "13016    1\n",
              "11453    2\n",
              "        ..\n",
              "1813     1\n",
              "1814     1\n",
              "1815     1\n",
              "1816     1\n",
              "1817     1\n",
              "Name: class, Length: 11110, dtype: int64"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-utGvMOD5Ma6"
      },
      "source": [
        "到这里以上完成training的resample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "9JoPcMR8NbCu"
      },
      "outputs": [],
      "source": [
        "glove_model = {}\n",
        "# with open(path + 'glove.6B.100d','r') as f:\n",
        "with open('glove.6B.100d','r') as f:\n",
        "    for line in f:\n",
        "        line = line.split()\n",
        "        word = line[0]\n",
        "        embedding = np.array(line[1:], dtype=np.float64)\n",
        "        glove_model[word] = embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "Ingwx50-Nefg"
      },
      "outputs": [],
      "source": [
        "# # make encoding in X match glove embedding\n",
        "vecs = np.zeros((len(glove_model), 100), dtype=np.float64)\n",
        "i = 0\n",
        "for word, embedding in glove_model.items():\n",
        "    vecs[i] = embedding\n",
        "    i += 1\n",
        "\n",
        "pad_vec = np.zeros((1,100))   # vector for padding\n",
        "\n",
        "unk_vec = np.mean(vecs, axis=0) # <unk>\n",
        "\n",
        "glove_embeddings = np.vstack((pad_vec, unk_vec, vecs))\n",
        "glove_vocab = list(glove_model.keys())\n",
        "glove_vocab.insert(0, '<unk>')\n",
        "glove_vocab.insert(0, '<pad>')\n",
        "word_index = {glove_vocab[i]:i for i in range(len(glove_vocab))}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "hGPljGpn5Ma8"
      },
      "outputs": [],
      "source": [
        "def encode_X(X_df):\n",
        "  X = [0] * len(X_df)\n",
        "  count = 0\n",
        "  for index, row in X_df.iterrows():\n",
        "      X[count] = []\n",
        "      for word in row['tweet']:\n",
        "          if word in glove_vocab:\n",
        "              X[count].append(word_index[word])\n",
        "          else:\n",
        "              X[count].append(word_index['<unk>'])\n",
        "      count += 1\n",
        "  return X\n",
        "\n",
        "# runtime: 3 minutes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "ZkihMQo47Qt9"
      },
      "outputs": [],
      "source": [
        "X_train = encode_X(X_train)\n",
        "X_val = encode_X(X_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWHxGW2v5Ma9",
        "outputId": "f8dfa885-c6c0-4434-9f0d-7512220c6cd1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "19826\n",
            "19826\n"
          ]
        }
      ],
      "source": [
        "print(len(X))\n",
        "print(len(y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "BFMHs1uQaMQ5"
      },
      "outputs": [],
      "source": [
        "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "class TrainData(Dataset):\n",
        "    def __init__(self, X, y, transform=None):\n",
        "        self.X = torch.transpose(pad_sequence([torch.Tensor(i) for i in X], padding_value=0), 0, 1).to(device)\n",
        "        self.y = y\n",
        "        self.lengths = [len(i) for i in X]\n",
        "        self.transform = transform\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        tweet = self.X[index]\n",
        "        label = self.y.iloc[index]\n",
        "        length = self.lengths[index]\n",
        "            \n",
        "        return tweet, length, label\n",
        "\n",
        "\n",
        "class TestData(Dataset):\n",
        "    def __init__(self, X, transform=None):\n",
        "      self.X = torch.transpose(pad_sequence([torch.Tensor(i) for i in X], padding_value=0), 0, 1).to(device)\n",
        "      self.lengths = [len(i) for i in X]\n",
        "\n",
        "      self.transform = transform\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        tweet = self.X[index]\n",
        "        length = self.lengths[index]\n",
        "            \n",
        "        return tweet, length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "ymVv-ek2aMTj"
      },
      "outputs": [],
      "source": [
        "train_data = TrainData(X_train, y_train, transform=transforms.ToTensor())\n",
        "val_data = TrainData(X_val, y_val, transform=transforms.ToTensor())\n",
        "batch_size = 20\n",
        "num_workers = 0\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
        "valid_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size, num_workers=num_workers, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOfkiGMrnWfG"
      },
      "source": [
        "# Model (DWMW17)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "zmKsHx43aMWT"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class LSTM(nn.Module):\n",
        "    def __init__(self, input_size, embed_dim, hidden_size, num_layers, num_classes, dropout):\n",
        "        super(LSTM, self).__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = nn.Embedding.from_pretrained(torch.from_numpy(glove_embeddings).float())\n",
        "        self.lstm = nn.LSTM(embed_dim, hidden_size, num_layers, batch_first=True)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear1 = nn.Linear(hidden_size, 128)\n",
        "        self.elu = nn.ELU()\n",
        "        self.fc = nn.Linear(128 , num_classes)\n",
        "        \n",
        "    def forward(self, x, lengths):\n",
        "        # Initialize hidden states and cell states\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) # one forward, one backward, so *2\n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
        "        x = x.int().to(device)\n",
        "        out = self.embedding(x)\n",
        "        out = pack_padded_sequence(out, lengths, batch_first=True, enforce_sorted=False)\n",
        "        out, _ = self.lstm(out, (h0, c0))\n",
        "        out, _ = pad_packed_sequence(out, batch_first=True)\n",
        "        out = self.linear1(out)\n",
        "        out = self.dropout(out)\n",
        "        out = self.elu(out)\n",
        "        out = self.fc(out)\n",
        "        out = out[:, -1, :]\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6p7-PjDt3lX",
        "outputId": "404a1177-b4c2-451b-a65d-1f902ca545ef"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LSTM(\n",
              "  (embedding): Embedding(400002, 100)\n",
              "  (lstm): LSTM(100, 256, batch_first=True)\n",
              "  (dropout): Dropout(p=0.33, inplace=False)\n",
              "  (linear1): Linear(in_features=256, out_features=128, bias=True)\n",
              "  (elu): ELU(alpha=1.0)\n",
              "  (fc): Linear(in_features=128, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "n_hidden = 256\n",
        "n_input = len(glove_embeddings)\n",
        "n_embed_dim = 100\n",
        "n_layers = 1\n",
        "n_classes = 3 # output layer\n",
        "dropout = 0.33\n",
        "lstm = LSTM(n_input, n_embed_dim, n_hidden, n_layers, n_classes, dropout)\n",
        "lstm.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXn9oJyf7fOH",
        "outputId": "97740bce-30a9-4b6d-93ee-9e9db3001365"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1 \tTraining Loss: 0.042348 \tValidation Loss: 0.000000\tLearning Rate: 0.500\n",
            "Epoch: 2 \tTraining Loss: 0.041949 \tValidation Loss: 0.000000\tLearning Rate: 0.500\n",
            "Epoch: 3 \tTraining Loss: 0.041673 \tValidation Loss: 0.000000\tLearning Rate: 0.500\n",
            "Epoch: 4 \tTraining Loss: 0.041626 \tValidation Loss: 0.000000\tLearning Rate: 0.500\n",
            "Epoch: 5 \tTraining Loss: 0.041545 \tValidation Loss: 0.000000\tLearning Rate: 0.500\n",
            "Epoch: 6 \tTraining Loss: 0.041521 \tValidation Loss: 0.000000\tLearning Rate: 0.500\n",
            "Epoch: 7 \tTraining Loss: 0.041434 \tValidation Loss: 0.000000\tLearning Rate: 0.500\n",
            "Epoch: 8 \tTraining Loss: 0.041394 \tValidation Loss: 0.000000\tLearning Rate: 0.500\n",
            "Epoch: 9 \tTraining Loss: 0.041373 \tValidation Loss: 0.000000\tLearning Rate: 0.500\n",
            "Epoch: 10 \tTraining Loss: 0.041337 \tValidation Loss: 0.000000\tLearning Rate: 0.500\n",
            "Epoch: 11 \tTraining Loss: 0.040950 \tValidation Loss: 0.000000\tLearning Rate: 0.250\n",
            "Epoch: 12 \tTraining Loss: 0.040991 \tValidation Loss: 0.000000\tLearning Rate: 0.250\n",
            "Epoch: 13 \tTraining Loss: 0.040929 \tValidation Loss: 0.000000\tLearning Rate: 0.250\n",
            "Epoch: 14 \tTraining Loss: 0.040938 \tValidation Loss: 0.000000\tLearning Rate: 0.250\n",
            "Epoch: 15 \tTraining Loss: 0.040830 \tValidation Loss: 0.000000\tLearning Rate: 0.250\n",
            "Epoch: 16 \tTraining Loss: 0.040757 \tValidation Loss: 0.000000\tLearning Rate: 0.250\n",
            "Epoch: 17 \tTraining Loss: 0.040820 \tValidation Loss: 0.000000\tLearning Rate: 0.250\n",
            "Epoch: 18 \tTraining Loss: 0.040708 \tValidation Loss: 0.000000\tLearning Rate: 0.250\n",
            "Epoch: 19 \tTraining Loss: 0.040689 \tValidation Loss: 0.000000\tLearning Rate: 0.250\n",
            "Epoch: 20 \tTraining Loss: 0.040633 \tValidation Loss: 0.000000\tLearning Rate: 0.250\n",
            "Epoch: 21 \tTraining Loss: 0.040574 \tValidation Loss: 0.000000\tLearning Rate: 0.125\n",
            "Epoch: 22 \tTraining Loss: 0.040469 \tValidation Loss: 0.000000\tLearning Rate: 0.125\n",
            "Epoch: 23 \tTraining Loss: 0.040576 \tValidation Loss: 0.000000\tLearning Rate: 0.125\n",
            "Epoch: 24 \tTraining Loss: 0.040540 \tValidation Loss: 0.000000\tLearning Rate: 0.125\n",
            "Epoch: 25 \tTraining Loss: 0.040454 \tValidation Loss: 0.000000\tLearning Rate: 0.125\n",
            "Epoch: 26 \tTraining Loss: 0.040539 \tValidation Loss: 0.000000\tLearning Rate: 0.125\n",
            "Epoch: 27 \tTraining Loss: 0.040508 \tValidation Loss: 0.000000\tLearning Rate: 0.125\n",
            "Epoch: 28 \tTraining Loss: 0.040461 \tValidation Loss: 0.000000\tLearning Rate: 0.125\n",
            "Epoch: 29 \tTraining Loss: 0.040353 \tValidation Loss: 0.000000\tLearning Rate: 0.125\n",
            "Epoch: 30 \tTraining Loss: 0.040414 \tValidation Loss: 0.000000\tLearning Rate: 0.125\n"
          ]
        }
      ],
      "source": [
        "learning_rate = 0.5\n",
        "n_epochs = 30\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(lstm.parameters(), lr=learning_rate)\n",
        "scheduler = MultiStepLR(optimizer, milestones=[10, 20, 50], gamma=0.5)\n",
        "# scheduler = CyclicLR(optimizer, base_lr=0.005, max_lr=0.5)\n",
        "train_loss_min = np.Inf # initialize minimum validation loss\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "  # initialize train and validation loss\n",
        "  train_loss = 0\n",
        "  valid_loss = 0\n",
        "\n",
        "\n",
        "  # train\n",
        "  # mini-batch gradient descent\n",
        "  lstm.train()\n",
        "  for i, (data, lengths, target) in enumerate(train_loader):\n",
        "    # forward\n",
        "    output = lstm(data, lengths)\n",
        "    loss = criterion(output, target)\n",
        "    optimizer.zero_grad()\n",
        "    # backward\n",
        "    loss.backward()\n",
        "    # update parameters\n",
        "    optimizer.step()\n",
        "    # track training loss\n",
        "    train_loss += loss.item()\n",
        "    # scheduler.step()\n",
        "\n",
        "\n",
        "  # evaluation\n",
        "  # lstm.eval()\n",
        "  # for i, (data,lengths, target) in enumerate(valid_loader):\n",
        "  #     # forward pass\n",
        "  #     output = lstm(data, lengths)\n",
        "  #     # calculate the loss\n",
        "  #     print(target)\n",
        "  #     loss = criterion(output, target)\n",
        "  #     # track validation loss\n",
        "  #     valid_loss += loss.item()\n",
        "\n",
        "\n",
        "  train_loss = train_loss/len(train_loader.dataset)\n",
        "  # valid_loss = valid_loss/len(valid_loader.dataset)\n",
        "  \n",
        "  print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}\\tLearning Rate: {:.3f}'.format(\n",
        "      epoch+1, \n",
        "      train_loss,\n",
        "      valid_loss,\n",
        "      scheduler.get_last_lr()[0]\n",
        "      ))\n",
        "  \n",
        "  # if train_loss <= train_loss_min:\n",
        "  #     print('Training loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
        "  #     train_loss_min,\n",
        "  #     train_loss))\n",
        "  #     torch.save(lstm.state_dict(), 'lstm_model.pt')\n",
        "  #     train_loss_min = train_loss\n",
        "\n",
        "  scheduler.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "wEba1_KMsiBk"
      },
      "outputs": [],
      "source": [
        "torch.save(lstm.state_dict(), 'lstm_model(dwmw17).pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "sAJxMdJuBRLd"
      },
      "outputs": [],
      "source": [
        "# run the split again\n",
        "X_train, X_test, y_train, y_test = train_test_split(df[['class', 'tweet', 'race']], df['class'], test_size = 0.2, stratify=df['toxic'], random_state=17)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size = 0.5, stratify=y_test, random_state=17)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "4E5LnysbaMaT"
      },
      "outputs": [],
      "source": [
        "# lstm.load_state_dict(torch.load(path+'lstm_model.pt'))\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def test():\n",
        "  test_data = TestData(encode_X(X_test), transform=transforms.ToTensor())\n",
        "  test_loader = torch.utils.data.DataLoader(test_data, batch_size=1, \n",
        "      num_workers=num_workers)\n",
        "  y_pred = []\n",
        "  lstm.eval()\n",
        "  with torch.no_grad():\n",
        "      for data, lengths in test_loader:\n",
        "          outputs = lstm(data, lengths)\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          y_pred.append(predicted.tolist()[0])\n",
        "\n",
        "  print(\"Test Accuracy: \" + str(accuracy_score(list(y_test), y_pred)))\n",
        "  print(\"Test F1 Score: \"+ str(f1_score(list(y_test), y_pred, average='micro')))\n",
        "  return y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-b7Pe4WN-NfI",
        "outputId": "b108d800-e442-44e4-ac32-afcf668d1815"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.8378378378378378\n",
            "Test F1 Score: 0.8378378378378378\n"
          ]
        }
      ],
      "source": [
        "y_pred = test()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "bCdwLw-Copoz"
      },
      "outputs": [],
      "source": [
        "# def predict():\n",
        "#   test_data = TestData(encode_X(df[['class', 'tweet', 'race']]), transform=transforms.ToTensor())\n",
        "#   test_loader = torch.utils.data.DataLoader(test_data, batch_size=1, \n",
        "#       num_workers=num_workers)\n",
        "#   y_pred = []\n",
        "#   lstm.eval()\n",
        "#   with torch.no_grad():\n",
        "#       for data, lengths in test_loader:\n",
        "#           outputs = lstm(data, lengths)\n",
        "#           _, predicted = torch.max(outputs.data, 1)\n",
        "#           y_pred.append(predicted.tolist()[0])\n",
        "#   return y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "s9iM0IopAUwk"
      },
      "outputs": [],
      "source": [
        "# y_pred = predict()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgLPExad7imb"
      },
      "source": [
        "# LSTM Bias Evalutaion (DWMW 17)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "T_K87VvH5Mba",
        "outputId": "8b3061d5-0424-438a-f80e-73b36e5a072e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "24783"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "LmwjVWUOF0v6",
        "outputId": "8a34446f-6d2e-4472-b792-915f42e484ab"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "      <th>tweet</th>\n",
              "      <th>race</th>\n",
              "      <th>toxic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>[rt, @mayasolovely, woman, ', complain, cleani...</td>\n",
              "      <td>3</td>\n",
              "      <td>non-toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>[rt, @mleew17, boy, dats, coldtyga, dwn, bad, ...</td>\n",
              "      <td>0</td>\n",
              "      <td>toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>[rt, @urkindofbrand, dawg, rt, @80sbaby4life, ...</td>\n",
              "      <td>0</td>\n",
              "      <td>toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>[rt, @c_g_anderson, @viva_based, look, like, t...</td>\n",
              "      <td>0</td>\n",
              "      <td>toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>[rt, @shenikaroberts, shit, hear, might, true,...</td>\n",
              "      <td>0</td>\n",
              "      <td>toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24778</th>\n",
              "      <td>1</td>\n",
              "      <td>[muthaf***, lie, &amp;#8220@lifeasking, @20_pearls...</td>\n",
              "      <td>0</td>\n",
              "      <td>toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24779</th>\n",
              "      <td>2</td>\n",
              "      <td>[', gone, broke, wrong, heart, baby, drove, re...</td>\n",
              "      <td>3</td>\n",
              "      <td>non-toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24780</th>\n",
              "      <td>1</td>\n",
              "      <td>[young, buck, wanna, eat, dat, nigguh, like, a...</td>\n",
              "      <td>0</td>\n",
              "      <td>toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24781</th>\n",
              "      <td>1</td>\n",
              "      <td>[youu, got, wild, bitches, tellin, lies]</td>\n",
              "      <td>0</td>\n",
              "      <td>toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24782</th>\n",
              "      <td>2</td>\n",
              "      <td>[~~ruffled, |, ntac, eileen, dahlia, -, beauti...</td>\n",
              "      <td>2</td>\n",
              "      <td>non-toxic</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>24783 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       class                                              tweet  race  \\\n",
              "0          2  [rt, @mayasolovely, woman, ', complain, cleani...     3   \n",
              "1          1  [rt, @mleew17, boy, dats, coldtyga, dwn, bad, ...     0   \n",
              "2          1  [rt, @urkindofbrand, dawg, rt, @80sbaby4life, ...     0   \n",
              "3          1  [rt, @c_g_anderson, @viva_based, look, like, t...     0   \n",
              "4          1  [rt, @shenikaroberts, shit, hear, might, true,...     0   \n",
              "...      ...                                                ...   ...   \n",
              "24778      1  [muthaf***, lie, &#8220@lifeasking, @20_pearls...     0   \n",
              "24779      2  [', gone, broke, wrong, heart, baby, drove, re...     3   \n",
              "24780      1  [young, buck, wanna, eat, dat, nigguh, like, a...     0   \n",
              "24781      1           [youu, got, wild, bitches, tellin, lies]     0   \n",
              "24782      2  [~~ruffled, |, ntac, eileen, dahlia, -, beauti...     2   \n",
              "\n",
              "           toxic  \n",
              "0      non-toxic  \n",
              "1          toxic  \n",
              "2          toxic  \n",
              "3          toxic  \n",
              "4          toxic  \n",
              "...          ...  \n",
              "24778      toxic  \n",
              "24779  non-toxic  \n",
              "24780      toxic  \n",
              "24781      toxic  \n",
              "24782  non-toxic  \n",
              "\n",
              "[24783 rows x 4 columns]"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "NPM8WlCp5Mba"
      },
      "outputs": [],
      "source": [
        "lstm_result = X_test.copy()\n",
        "# lstm_result = lstm_result.reindex(np.arange(len(X)))\n",
        "# lstm_result.loc[indices_train, 'data_type'] = 'train'\n",
        "# lstm_result.loc[indices_val, 'data_type'] = 'val'\n",
        "# lstm_result.loc[indices_test, 'data_type'] = 'test'\n",
        "lstm_result['pred'] = y_pred\n",
        "# lstm_result = lstm_result.loc[lstm_result['data_type']=='test'][['class', 'pred', 'race']]\n",
        "aae_group = lstm_result.loc[lstm_result['race'] == 0]\n",
        "other_group = lstm_result.loc[lstm_result['race'] != 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "iZGZt8jg5Mbb"
      },
      "outputs": [],
      "source": [
        "def fpr(cm):\n",
        "  FP = cm.sum(axis=0) - np.diag(cm)  \n",
        "  FN = cm.sum(axis=1) - np.diag(cm)\n",
        "  TP = np.diag(cm)\n",
        "  TN = cm.sum() - (FP + FN + TP)\n",
        "  FPR = FP/(FP+TN)\n",
        "  return FPR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLgfLGop5Mbb",
        "outputId": "df5c10dd-98bf-4af3-be8b-8f5647fdde42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LSTM Bias Evaluation: \n",
            "\tHate Speech Offensive  Neither\n",
            "AAE\t[0.00080841 0.67692308 0.043654  ]\n",
            "Non-AAE\t[0.00091408 0.3816092  0.11151515]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "print(\"LSTM Bias Evaluation: \")\n",
        "print('\\tHate Speech' + ' Offensive' + '  Neither')\n",
        "aae_cm = confusion_matrix(aae_group['class'], aae_group['pred'])\n",
        "print(\"AAE\" + '\\t' + str(fpr(aae_cm)))\n",
        "other_cm = confusion_matrix(other_group['class'], other_group['pred'])\n",
        "print(\"Non-AAE\" + '\\t' + str(fpr(other_cm)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KcypRrbxTHj"
      },
      "source": [
        "# Data Preprocessing (FDCL18)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "WO2H3LNjxZh3"
      },
      "outputs": [],
      "source": [
        "fdcl18_data = pd.read_csv('FDCL18.csv', delimiter='\\t', nrows=None, skiprows=2, header=None, names=['tweet', 'label', 'count'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "QRXGkvSRzrpY"
      },
      "outputs": [],
      "source": [
        "df1 = fdcl18_data[['tweet', 'label']].copy()\n",
        "df1.loc[df1.label == 'hateful', 'label'] = 0\n",
        "df1.loc[df1.label == 'abusive', 'label'] = 1\n",
        "df1.loc[df1.label == 'spam', 'label'] = 2\n",
        "df1.loc[df1.label == 'normal', 'label'] = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycUY_Kb27onN",
        "outputId": "aef7acbe-4b81-4e35-d703-7b066fa765aa"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/b0/1rd8yjhd26992klldm8y9hgr0000gn/T/ipykernel_87492/1334587656.py:7: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
            "  df1['tweet'] = df1['tweet'].str.replace(punct_sign, '')\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/luvlzf/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "/var/folders/b0/1rd8yjhd26992klldm8y9hgr0000gn/T/ipykernel_87492/1334587656.py:20: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  df1['tweet'] = df1['tweet'].str.replace(regex_stopword, '')\n"
          ]
        }
      ],
      "source": [
        "# preprocessing\n",
        "df1['tweet'] = df1['tweet'].apply(lambda x:x.lower())\n",
        "punctuation_signs = list(\"?:!.,;\")\n",
        "df1['tweet'] = df1['tweet']\n",
        "\n",
        "for punct_sign in punctuation_signs:   \n",
        "    df1['tweet'] = df1['tweet'].str.replace(punct_sign, '')\n",
        "\n",
        "df1['tweet'] = df1['tweet'].apply(lambda x: x.replace('\\n', ' '))\n",
        "df1['tweet'] = df1['tweet'].apply(lambda x: x.replace('\\t', ' '))\n",
        "df1['tweet'] = df1['tweet'].str.replace(\"    \", \" \")\n",
        "df1['tweet'] = df1['tweet'].str.replace('\"', '')\n",
        "df1['tweet'] = df1['tweet'].str.replace(\"'s\", \"\")\n",
        "\n",
        "# remove stop words\n",
        "nltk.download('stopwords')\n",
        "stop_words = list(stopwords.words('english'))\n",
        "for stop_word in stop_words:\n",
        "    regex_stopword = r\"\\b\" + stop_word + r\"\\b\"\n",
        "    df1['tweet'] = df1['tweet'].str.replace(regex_stopword, '')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "hzl1sFgd5MbJ",
        "outputId": "c8b2f2df-ff8e-4b97-dc01-5eaedddabdd5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "99995\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>rt @papapishu man  would fucking rule     part...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>time  draw close   &amp;#128591&amp;#127995 father  ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>notice  start  act different  distant  bc  p...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>forget unfollowers  believe  growing 7 new fol...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>rt @vitiligoprince hate  sexually frustrated l...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>topped  group  tgp disc jam season 2 onto  sem...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>daily baby aspirin   #heart  might  preventin...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>liked  @youtube video  @mattshea https//tco/n...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>rt @lestuhgang_   fucking  &amp;amp  homies dont t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>uber finds one allegedly stolen waymo file –  ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               tweet label\n",
              "0  rt @papapishu man  would fucking rule     part...     1\n",
              "1    time  draw close   &#128591&#127995 father  ...     3\n",
              "2    notice  start  act different  distant  bc  p...     3\n",
              "3  forget unfollowers  believe  growing 7 new fol...     3\n",
              "4  rt @vitiligoprince hate  sexually frustrated l...     1\n",
              "5  topped  group  tgp disc jam season 2 onto  sem...     3\n",
              "6   daily baby aspirin   #heart  might  preventin...     3\n",
              "7   liked  @youtube video  @mattshea https//tco/n...     3\n",
              "8  rt @lestuhgang_   fucking  &amp  homies dont t...     1\n",
              "9  uber finds one allegedly stolen waymo file –  ...     2"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(len(df1))\n",
        "df1.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "kWD54YO78RJQ"
      },
      "outputs": [],
      "source": [
        "df1['tweet'] = df1['tweet'].str.split()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "dWyzwMK45MbK"
      },
      "outputs": [],
      "source": [
        "# African-American, Hispanic, Asian, and White topics,\n",
        "aae = np.genfromtxt('fdcl18_aae.csv', delimiter=',')\n",
        "df1['race'] = aae.argmax(axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "WcXHW4I75MbK",
        "outputId": "d74f012c-1ae2-4108-efb3-0851fd53f071"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "99995\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "      <th>race</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[rt, @papapishu, man, would, fucking, rule, pa...</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[time, draw, close, &amp;#128591&amp;#127995, father, ...</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[notice, start, act, different, distant, bc, p...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[forget, unfollowers, believe, growing, 7, new...</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[rt, @vitiligoprince, hate, sexually, frustrat...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>[topped, group, tgp, disc, jam, season, 2, ont...</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>[daily, baby, aspirin, #heart, might, preventi...</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>[liked, @youtube, video, @mattshea, https//tco...</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>[rt, @lestuhgang_, fucking, &amp;amp, homies, dont...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>[uber, finds, one, allegedly, stolen, waymo, f...</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               tweet label  race\n",
              "0  [rt, @papapishu, man, would, fucking, rule, pa...     1     3\n",
              "1  [time, draw, close, &#128591&#127995, father, ...     3     3\n",
              "2  [notice, start, act, different, distant, bc, p...     3     0\n",
              "3  [forget, unfollowers, believe, growing, 7, new...     3     3\n",
              "4  [rt, @vitiligoprince, hate, sexually, frustrat...     1     0\n",
              "5  [topped, group, tgp, disc, jam, season, 2, ont...     3     3\n",
              "6  [daily, baby, aspirin, #heart, might, preventi...     3     3\n",
              "7  [liked, @youtube, video, @mattshea, https//tco...     3     3\n",
              "8  [rt, @lestuhgang_, fucking, &amp, homies, dont...     1     1\n",
              "9  [uber, finds, one, allegedly, stolen, waymo, f...     2     3"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(len(df1))\n",
        "df1.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "DWux7ozy5MbL"
      },
      "outputs": [],
      "source": [
        "def is_toxic(label):\n",
        "    if label == 0 or label == 1:\n",
        "        return 'toxic' # toxic\n",
        "    else:\n",
        "        return 'non-toxic' # non-toxic\n",
        "    \n",
        "df1['toxic'] = df1['label'].apply(is_toxic)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [],
      "source": [
        "indices = np.arange(len(df))\n",
        "X_train, X_test, y_train, y_test = train_test_split(df1[['tweet', 'label', 'race']], df1['toxic'], test_size = 0.2, stratify=df1['toxic'], random_state=17)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size = 0.5, stratify=y_test, random_state=17)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "XChhAk0i5MbL"
      },
      "source": [
        "### Resample training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "HStc_50c5MbM",
        "outputId": "ed6557b9-717c-4e65-feb1-f07282e1bf5a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "      <th>race</th>\n",
              "      <th>toxic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[rt, @papapishu, man, would, fucking, rule, pa...</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[time, draw, close, &amp;#128591&amp;#127995, father, ...</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>non-toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[notice, start, act, different, distant, bc, p...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>non-toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[forget, unfollowers, believe, growing, 7, new...</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>non-toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[rt, @vitiligoprince, hate, sexually, frustrat...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>[topped, group, tgp, disc, jam, season, 2, ont...</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>non-toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>[daily, baby, aspirin, #heart, might, preventi...</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>non-toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>[liked, @youtube, video, @mattshea, https//tco...</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>non-toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>[rt, @lestuhgang_, fucking, &amp;amp, homies, dont...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>[uber, finds, one, allegedly, stolen, waymo, f...</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>non-toxic</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               tweet label  race      toxic\n",
              "0  [rt, @papapishu, man, would, fucking, rule, pa...     1     3      toxic\n",
              "1  [time, draw, close, &#128591&#127995, father, ...     3     3  non-toxic\n",
              "2  [notice, start, act, different, distant, bc, p...     3     0  non-toxic\n",
              "3  [forget, unfollowers, believe, growing, 7, new...     3     3  non-toxic\n",
              "4  [rt, @vitiligoprince, hate, sexually, frustrat...     1     0      toxic\n",
              "5  [topped, group, tgp, disc, jam, season, 2, ont...     3     3  non-toxic\n",
              "6  [daily, baby, aspirin, #heart, might, preventi...     3     3  non-toxic\n",
              "7  [liked, @youtube, video, @mattshea, https//tco...     3     3  non-toxic\n",
              "8  [rt, @lestuhgang_, fucking, &amp, homies, dont...     1     1      toxic\n",
              "9  [uber, finds, one, allegedly, stolen, waymo, f...     2     3  non-toxic"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df1.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "ybxeRf8z5MbN"
      },
      "outputs": [],
      "source": [
        "# Separate the features and labels\n",
        "X = X_train # race: 0 African American, 1, 2, 3\n",
        "y = y_train\n",
        "\n",
        "# Split the data into AAE and non-AAE\n",
        "X_aae = X[X['race'] == 0]\n",
        "X_non_aae = X[X['race'] != 0]\n",
        "\n",
        "y_aae = y[X['race'] == 0]\n",
        "y_non_aae = y[X['race'] != 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "3R-PCPRL5MbN",
        "outputId": "d4fa45f1-e818-47b9-8b08-0829a4871a42"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "      <th>race</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>12871</th>\n",
              "      <td>[good, suit, man’, flattering, fashion, item, ...</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7557</th>\n",
              "      <td>[epic, concept, album, proggy, metalheads, @ma...</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67861</th>\n",
              "      <td>[@blackpyramidofficial, outta, jersey, @embell...</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13992</th>\n",
              "      <td>[lmaoooo, fucking, hate, guy, &amp;#128557&amp;#128557...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99971</th>\n",
              "      <td>[unfollow, im, tweeting, rest, fucking, life, ...</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87559</th>\n",
              "      <td>[immediate, response, lets, fucking, go, couti...</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19556</th>\n",
              "      <td>[found, transponder, snail, behind--scenes, lo...</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14823</th>\n",
              "      <td>[@krgpryal, @cjprender, wow, staggering, painf...</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93624</th>\n",
              "      <td>[apple, name, 10th, anniversary, smartphone, '...</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77663</th>\n",
              "      <td>[#ftp, attacked, 13916275112()united, states#b...</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>70272 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   tweet label  race\n",
              "12871  [good, suit, man’, flattering, fashion, item, ...     3     3\n",
              "7557   [epic, concept, album, proggy, metalheads, @ma...     3     3\n",
              "67861  [@blackpyramidofficial, outta, jersey, @embell...     3     3\n",
              "13992  [lmaoooo, fucking, hate, guy, &#128557&#128557...     1     1\n",
              "99971  [unfollow, im, tweeting, rest, fucking, life, ...     1     3\n",
              "...                                                  ...   ...   ...\n",
              "87559  [immediate, response, lets, fucking, go, couti...     1     3\n",
              "19556  [found, transponder, snail, behind--scenes, lo...     3     3\n",
              "14823  [@krgpryal, @cjprender, wow, staggering, painf...     3     3\n",
              "93624  [apple, name, 10th, anniversary, smartphone, '...     3     3\n",
              "77663  [#ftp, attacked, 13916275112()united, states#b...     3     3\n",
              "\n",
              "[70272 rows x 3 columns]"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_non_aae"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "adJChFv95MbO",
        "outputId": "647e22ca-e783-4fa2-e97f-467f26d4c1aa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "12871    non-toxic\n",
              "7557     non-toxic\n",
              "67861    non-toxic\n",
              "13992        toxic\n",
              "99971        toxic\n",
              "           ...    \n",
              "87559        toxic\n",
              "19556    non-toxic\n",
              "14823    non-toxic\n",
              "93624    non-toxic\n",
              "77663    non-toxic\n",
              "Name: toxic, Length: 70272, dtype: object"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_non_aae"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "QliAN9LH5MbO",
        "outputId": "55064d54-e682-4e9a-ad97-70a236b842c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "51086\n",
            "19186\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "2.6626706973835086"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Calculate the non-toxic to toxic ratio in non-AAE\n",
        "print(sum(y_non_aae == 'non-toxic'))\n",
        "print(sum(y_non_aae == 'toxic'))\n",
        "ratio_non_aae = sum(y_non_aae == 'non-toxic') / sum(y_non_aae == 'toxic')\n",
        "ratio_non_aae"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "jOlOMCAs5MbP",
        "outputId": "ab59248f-5ec6-454e-fd7a-767c0fa2e915"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3218\n",
            "6506\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.4946203504457424"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Calculate the non-toxic to toxic ratio in AAE\n",
        "print(sum(y_aae == 'non-toxic'))\n",
        "print(sum(y_aae == 'toxic'))\n",
        "ratio_aae = sum(y_aae == 'non-toxic') / sum(y_aae == 'toxic')\n",
        "ratio_aae"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "dnjUFJMG5MbQ"
      },
      "outputs": [],
      "source": [
        "# Undersample the toxic tweets in AAE to match the ratio in non-AAE\n",
        "rus = RandomUnderSampler(sampling_strategy={ 'toxic': int(sum(y_aae == 'non-toxic') / ratio_non_aae) })\n",
        "X_aae_resampled, y_aae_resampled = rus.fit_resample(X_aae, y_aae)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "xee4-CCF5MbR"
      },
      "outputs": [],
      "source": [
        "# Combine the oversampled AAE data and the non-AAE data\n",
        "X_resampled = pd.concat([X_non_aae, X_aae_resampled])\n",
        "y_resampled = pd.concat([y_non_aae, y_aae_resampled])\n",
        "\n",
        "# Combine the features and labels back into a data frame\n",
        "df1_resampled = pd.concat([X_resampled, y_resampled], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "EREmOFKN5MbR"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "      <th>race</th>\n",
              "      <th>toxic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>12871</th>\n",
              "      <td>[good, suit, man’, flattering, fashion, item, ...</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>non-toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7557</th>\n",
              "      <td>[epic, concept, album, proggy, metalheads, @ma...</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>non-toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67861</th>\n",
              "      <td>[@blackpyramidofficial, outta, jersey, @embell...</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>non-toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13992</th>\n",
              "      <td>[lmaoooo, fucking, hate, guy, &amp;#128557&amp;#128557...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99971</th>\n",
              "      <td>[unfollow, im, tweeting, rest, fucking, life, ...</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4421</th>\n",
              "      <td>[rt, @emaaataylorrr, &amp;#128166&amp;#128175&amp;#128152&amp;...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4422</th>\n",
              "      <td>[bruh, fucking, lineup, @_richyrozay_, https//...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4423</th>\n",
              "      <td>[rt, @c_liveee, niece, fucked, em, baby, @_lub...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4424</th>\n",
              "      <td>[rt, @13reasonsfans, fucked, https//tco/58gm0y...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4425</th>\n",
              "      <td>[got, fucking, called, cuz, gc, im, said, rodr...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>toxic</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>74698 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   tweet label  race  \\\n",
              "12871  [good, suit, man’, flattering, fashion, item, ...     3     3   \n",
              "7557   [epic, concept, album, proggy, metalheads, @ma...     3     3   \n",
              "67861  [@blackpyramidofficial, outta, jersey, @embell...     3     3   \n",
              "13992  [lmaoooo, fucking, hate, guy, &#128557&#128557...     1     1   \n",
              "99971  [unfollow, im, tweeting, rest, fucking, life, ...     1     3   \n",
              "...                                                  ...   ...   ...   \n",
              "4421   [rt, @emaaataylorrr, &#128166&#128175&#128152&...     1     0   \n",
              "4422   [bruh, fucking, lineup, @_richyrozay_, https//...     1     0   \n",
              "4423   [rt, @c_liveee, niece, fucked, em, baby, @_lub...     1     0   \n",
              "4424   [rt, @13reasonsfans, fucked, https//tco/58gm0y...     1     0   \n",
              "4425   [got, fucking, called, cuz, gc, im, said, rodr...     1     0   \n",
              "\n",
              "           toxic  \n",
              "12871  non-toxic  \n",
              "7557   non-toxic  \n",
              "67861  non-toxic  \n",
              "13992      toxic  \n",
              "99971      toxic  \n",
              "...          ...  \n",
              "4421       toxic  \n",
              "4422       toxic  \n",
              "4423       toxic  \n",
              "4424       toxic  \n",
              "4425       toxic  \n",
              "\n",
              "[74698 rows x 4 columns]"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df1_resampled # X_train and y_train concatenated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "r7zxWr4h5MbS",
        "outputId": "f33e5b22-2f7d-4f7c-9a1a-9c1811a1b5fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "74698\n",
            "99995\n"
          ]
        }
      ],
      "source": [
        "print(len(df1_resampled))\n",
        "print(len(df1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "py0gcQF15MbT",
        "outputId": "906134be-d298-4a99-97b3-248401b8b0e3"
      },
      "outputs": [],
      "source": [
        "X_train = df1_resampled[['tweet', 'race', 'toxic']]\n",
        "y_train = df1_resampled['label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "Vnc-XtSm9JLF",
        "outputId": "99dba137-8763-4445-e90b-c6863997fe7a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "99995"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y = df1['label']\n",
        "len(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "lowjUK7pKpAJ"
      },
      "outputs": [],
      "source": [
        "X_train = encode_X(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "GbKrUHiz9El2"
      },
      "outputs": [],
      "source": [
        "train_data = TrainData(X_train, y_train, transform=transforms.ToTensor())\n",
        "# val_data = TrainData(X_val, y_val, transform=transforms.ToTensor())\n",
        "batch_size = 60\n",
        "num_workers = 0\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
        "# valid_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, num_workers=num_workers, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfJvO4AZ6eTa"
      },
      "source": [
        "# Model (FDCL18)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VB8jJdAq6hGn",
        "outputId": "43005386-d49e-422e-b6a7-c58b18c74b4f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LSTM(\n",
              "  (embedding): Embedding(400002, 100)\n",
              "  (lstm): LSTM(100, 256, batch_first=True)\n",
              "  (dropout): Dropout(p=0.33, inplace=False)\n",
              "  (linear1): Linear(in_features=256, out_features=128, bias=True)\n",
              "  (elu): ELU(alpha=1.0)\n",
              "  (fc): Linear(in_features=128, out_features=4, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "n_hidden = 256\n",
        "n_input = len(glove_embeddings)\n",
        "n_embed_dim = 100\n",
        "n_layers = 1\n",
        "n_classes = 4 # output layer\n",
        "dropout = 0.33\n",
        "lstm = LSTM(n_input, n_embed_dim, n_hidden, n_layers, n_classes, dropout)\n",
        "lstm.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2plwvU-14YG_",
        "outputId": "1656f166-f8b1-405f-8971-1a9c0d50ddab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1 \tTraining Loss: 0.017928 \tValidation Loss: 0.000000\tLearning Rate: 0.500\n",
            "Training loss decreased (inf --> 0.017928).  Saving model ...\n",
            "Epoch: 2 \tTraining Loss: 0.017867 \tValidation Loss: 0.000000\tLearning Rate: 0.500\n",
            "Training loss decreased (0.017928 --> 0.017867).  Saving model ...\n",
            "Epoch: 3 \tTraining Loss: 0.017818 \tValidation Loss: 0.000000\tLearning Rate: 0.500\n",
            "Training loss decreased (0.017867 --> 0.017818).  Saving model ...\n",
            "Epoch: 4 \tTraining Loss: 0.017792 \tValidation Loss: 0.000000\tLearning Rate: 0.500\n",
            "Training loss decreased (0.017818 --> 0.017792).  Saving model ...\n",
            "Epoch: 5 \tTraining Loss: 0.017777 \tValidation Loss: 0.000000\tLearning Rate: 0.500\n",
            "Training loss decreased (0.017792 --> 0.017777).  Saving model ...\n",
            "Epoch: 6 \tTraining Loss: 0.017776 \tValidation Loss: 0.000000\tLearning Rate: 0.500\n",
            "Training loss decreased (0.017777 --> 0.017776).  Saving model ...\n",
            "Epoch: 7 \tTraining Loss: 0.017763 \tValidation Loss: 0.000000\tLearning Rate: 0.500\n",
            "Training loss decreased (0.017776 --> 0.017763).  Saving model ...\n",
            "Epoch: 8 \tTraining Loss: 0.017759 \tValidation Loss: 0.000000\tLearning Rate: 0.500\n",
            "Training loss decreased (0.017763 --> 0.017759).  Saving model ...\n",
            "Epoch: 9 \tTraining Loss: 0.017756 \tValidation Loss: 0.000000\tLearning Rate: 0.500\n",
            "Training loss decreased (0.017759 --> 0.017756).  Saving model ...\n",
            "Epoch: 10 \tTraining Loss: 0.017740 \tValidation Loss: 0.000000\tLearning Rate: 0.500\n",
            "Training loss decreased (0.017756 --> 0.017740).  Saving model ...\n",
            "Epoch: 11 \tTraining Loss: 0.017728 \tValidation Loss: 0.000000\tLearning Rate: 0.250\n",
            "Training loss decreased (0.017740 --> 0.017728).  Saving model ...\n",
            "Epoch: 12 \tTraining Loss: 0.017715 \tValidation Loss: 0.000000\tLearning Rate: 0.250\n",
            "Training loss decreased (0.017728 --> 0.017715).  Saving model ...\n",
            "Epoch: 13 \tTraining Loss: 0.017727 \tValidation Loss: 0.000000\tLearning Rate: 0.250\n",
            "Epoch: 14 \tTraining Loss: 0.017704 \tValidation Loss: 0.000000\tLearning Rate: 0.250\n",
            "Training loss decreased (0.017715 --> 0.017704).  Saving model ...\n",
            "Epoch: 15 \tTraining Loss: 0.017691 \tValidation Loss: 0.000000\tLearning Rate: 0.250\n",
            "Training loss decreased (0.017704 --> 0.017691).  Saving model ...\n",
            "Epoch: 16 \tTraining Loss: 0.017715 \tValidation Loss: 0.000000\tLearning Rate: 0.250\n",
            "Epoch: 17 \tTraining Loss: 0.017694 \tValidation Loss: 0.000000\tLearning Rate: 0.250\n",
            "Epoch: 18 \tTraining Loss: 0.017702 \tValidation Loss: 0.000000\tLearning Rate: 0.250\n",
            "Epoch: 19 \tTraining Loss: 0.017704 \tValidation Loss: 0.000000\tLearning Rate: 0.250\n",
            "Epoch: 20 \tTraining Loss: 0.017703 \tValidation Loss: 0.000000\tLearning Rate: 0.250\n",
            "Epoch: 21 \tTraining Loss: 0.017684 \tValidation Loss: 0.000000\tLearning Rate: 0.125\n",
            "Training loss decreased (0.017691 --> 0.017684).  Saving model ...\n",
            "Epoch: 22 \tTraining Loss: 0.017685 \tValidation Loss: 0.000000\tLearning Rate: 0.125\n",
            "Epoch: 23 \tTraining Loss: 0.017681 \tValidation Loss: 0.000000\tLearning Rate: 0.125\n",
            "Training loss decreased (0.017684 --> 0.017681).  Saving model ...\n",
            "Epoch: 24 \tTraining Loss: 0.017681 \tValidation Loss: 0.000000\tLearning Rate: 0.125\n",
            "Epoch: 25 \tTraining Loss: 0.017663 \tValidation Loss: 0.000000\tLearning Rate: 0.125\n",
            "Training loss decreased (0.017681 --> 0.017663).  Saving model ...\n",
            "Epoch: 26 \tTraining Loss: 0.017684 \tValidation Loss: 0.000000\tLearning Rate: 0.125\n",
            "Epoch: 27 \tTraining Loss: 0.017677 \tValidation Loss: 0.000000\tLearning Rate: 0.125\n",
            "Epoch: 28 \tTraining Loss: 0.017680 \tValidation Loss: 0.000000\tLearning Rate: 0.125\n",
            "Epoch: 29 \tTraining Loss: 0.017678 \tValidation Loss: 0.000000\tLearning Rate: 0.125\n",
            "Epoch: 30 \tTraining Loss: 0.017669 \tValidation Loss: 0.000000\tLearning Rate: 0.125\n"
          ]
        }
      ],
      "source": [
        "learning_rate = 0.5\n",
        "n_epochs = 30\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(lstm.parameters(), lr=learning_rate)\n",
        "scheduler = MultiStepLR(optimizer, milestones=[10, 20, 50], gamma=0.5)\n",
        "# scheduler = CyclicLR(optimizer, base_lr=0.005, max_lr=0.5)\n",
        "train_loss_min = np.Inf # initialize minimum validation loss\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "  # initialize train and validation loss\n",
        "  train_loss = 0\n",
        "  valid_loss = 0\n",
        "\n",
        "\n",
        "  # train\n",
        "  # mini-batch gradient descent\n",
        "  lstm.train()\n",
        "  for i, (data, lengths, target) in enumerate(train_loader):\n",
        "    # forward\n",
        "    output = lstm(data, lengths)\n",
        "    loss = criterion(output, target)\n",
        "    optimizer.zero_grad()\n",
        "    # backward\n",
        "    loss.backward()\n",
        "    # update parameters\n",
        "    optimizer.step()\n",
        "    # track training loss\n",
        "    train_loss += loss.item()\n",
        "    # scheduler.step()\n",
        "\n",
        "\n",
        "  # evaluation\n",
        "  # lstm.eval()\n",
        "  # for i, (data,lengths, target) in enumerate(valid_loader):\n",
        "  #     # forward pass\n",
        "  #     output = lstm(data, lengths)\n",
        "  #     # calculate the loss\n",
        "  #     loss = criterion(output, target)\n",
        "  #     # track validation loss\n",
        "  #     valid_loss += loss.item()\n",
        "\n",
        "\n",
        "  train_loss = train_loss/len(train_loader.dataset)\n",
        "  valid_loss = valid_loss/len(valid_loader.dataset)\n",
        "  \n",
        "  print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}\\tLearning Rate: {:.3f}'.format(\n",
        "      epoch+1, \n",
        "      train_loss,\n",
        "      valid_loss,\n",
        "      scheduler.get_last_lr()[0]\n",
        "      ))\n",
        "  \n",
        "  if train_loss <= train_loss_min:\n",
        "      print('Training loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
        "      train_loss_min,\n",
        "      train_loss))\n",
        "      torch.save(lstm.state_dict(), 'lstm_model.pt')\n",
        "      train_loss_min = train_loss\n",
        "\n",
        "  scheduler.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "tBuego-R-SOW"
      },
      "outputs": [],
      "source": [
        "torch.save(lstm.state_dict(), 'lstm_model(fdcl18).pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "      <th>race</th>\n",
              "      <th>toxic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[rt, @papapishu, man, would, fucking, rule, pa...</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[time, draw, close, &amp;#128591&amp;#127995, father, ...</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>non-toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[notice, start, act, different, distant, bc, p...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>non-toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[forget, unfollowers, believe, growing, 7, new...</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>non-toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[rt, @vitiligoprince, hate, sexually, frustrat...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99990</th>\n",
              "      <td>[rt, @shangros, fucking, queen, https//tco/wax...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99991</th>\n",
              "      <td>[#osteporosis, treated, #pemf, -, rebuild, bon...</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>non-toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99992</th>\n",
              "      <td>[@lgusamobile, phone, screen, keeps, flickring...</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>non-toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99993</th>\n",
              "      <td>[#bigdata, vs, #reality, equally, applies, #ec...</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>non-toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99994</th>\n",
              "      <td>[whatever, choose, first, get, know, willing, ...</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>non-toxic</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>99995 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   tweet label  race  \\\n",
              "0      [rt, @papapishu, man, would, fucking, rule, pa...     1     3   \n",
              "1      [time, draw, close, &#128591&#127995, father, ...     3     3   \n",
              "2      [notice, start, act, different, distant, bc, p...     3     0   \n",
              "3      [forget, unfollowers, believe, growing, 7, new...     3     3   \n",
              "4      [rt, @vitiligoprince, hate, sexually, frustrat...     1     0   \n",
              "...                                                  ...   ...   ...   \n",
              "99990  [rt, @shangros, fucking, queen, https//tco/wax...     1     1   \n",
              "99991  [#osteporosis, treated, #pemf, -, rebuild, bon...     3     3   \n",
              "99992  [@lgusamobile, phone, screen, keeps, flickring...     3     3   \n",
              "99993  [#bigdata, vs, #reality, equally, applies, #ec...     3     3   \n",
              "99994  [whatever, choose, first, get, know, willing, ...     3     3   \n",
              "\n",
              "           toxic  \n",
              "0          toxic  \n",
              "1      non-toxic  \n",
              "2      non-toxic  \n",
              "3      non-toxic  \n",
              "4          toxic  \n",
              "...          ...  \n",
              "99990      toxic  \n",
              "99991  non-toxic  \n",
              "99992  non-toxic  \n",
              "99993  non-toxic  \n",
              "99994  non-toxic  \n",
              "\n",
              "[99995 rows x 4 columns]"
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {},
      "outputs": [],
      "source": [
        "# run the split again\n",
        "X_train, X_test, y_train, y_test = train_test_split(df1[['label', 'tweet', 'race']], df1['label'], test_size = 0.2, stratify=df1['label'], random_state=17)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size = 0.5, stratify=y_test, random_state=17)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRIOeNGBAZ2Z",
        "outputId": "41028dbb-8e7e-4dc4-9c9a-5b16ab26e850"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.7678\n",
            "Test F1 Score: 0.7678\n"
          ]
        }
      ],
      "source": [
        "y_pred = test()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S01wsVNV6vt3"
      },
      "outputs": [],
      "source": [
        "# df1['pred'] = y_pred\n",
        "# with open('lstm_pred(fdcl18).csv', 'w') as f:\n",
        "#   f.write('tweet,label,pred')\n",
        "#   for index, row in df1.iterrows():\n",
        "#     f.write(str(row['tweet'])+ ',' + str(row['label']) + ','+ str(row['pred']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdb-ljsO5Mbc"
      },
      "source": [
        "# LSTM Bias Evaluation (FDCL18)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "T9QX7RdW5Mbc"
      },
      "outputs": [],
      "source": [
        "lstm_result = X_test.copy()\n",
        "lstm_result['pred'] = y_pred\n",
        "aae_group = lstm_result.loc[lstm_result['race'] == 0]\n",
        "other_group = lstm_result.loc[lstm_result['race'] != 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 0, 3, 2], dtype=object)"
            ]
          },
          "execution_count": 118,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "aae_group['label'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label    object\n",
            "tweet    object\n",
            "race      int64\n",
            "pred      int64\n",
            "dtype: object\n"
          ]
        }
      ],
      "source": [
        "print(aae_group.dtypes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/b0/1rd8yjhd26992klldm8y9hgr0000gn/T/ipykernel_87492/1611011738.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  aae_group['label'] = aae_group['label'].astype('int64')\n"
          ]
        }
      ],
      "source": [
        "aae_group['label'] = aae_group['label'].astype('int64')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label     int64\n",
            "tweet    object\n",
            "race      int64\n",
            "pred      int64\n",
            "dtype: object\n"
          ]
        }
      ],
      "source": [
        "print(aae_group.dtypes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/b0/1rd8yjhd26992klldm8y9hgr0000gn/T/ipykernel_87492/2531155045.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  other_group['label'] = other_group['label'].astype('int64')\n"
          ]
        }
      ],
      "source": [
        "other_group['label'] = other_group['label'].astype('int64')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "id": "f2pmu6b_LoXE"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LSTM Bias Evaluation: \n",
            "\tHate Speech Offensive  Spam       Neither\n",
            "AAE\t[0.         0.3250478  0.05741627 0.10273224]\n",
            "Non-AAE\t[0.         0.07763975 0.06634004 0.2627027 ]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "print(\"LSTM Bias Evaluation: \")\n",
        "print('\\tHate Speech' + ' Offensive' + '  Spam' + '       Neither')\n",
        "aae_cm = confusion_matrix(aae_group['label'], aae_group['pred'])\n",
        "print(\"AAE\" + '\\t' + str(fpr(aae_cm)))\n",
        "other_cm = confusion_matrix(other_group['label'], other_group['pred'])\n",
        "print(\"Non-AAE\" + '\\t' + str(fpr(other_cm)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjpQzx9peonQ"
      },
      "source": [
        "# References:\n",
        "https://stackoverflow.com/questions/31324218/scikit-learn-how-to-obtain-true-positive-true-negative-false-positive-and-fal"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
